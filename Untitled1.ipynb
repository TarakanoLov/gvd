{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "# from keras.models import Model\n",
    "from keras.layers import Dense, Input, concatenate, Flatten, Multiply, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# import keras.callbacks as cb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from joblib import dump, load\n",
    "import critic_model\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name):\n",
    "    with open(name) as json_file:\n",
    "         data = json.load(json_file)\n",
    "    \n",
    "    \n",
    "    data = data['data']\n",
    "        \n",
    "        \n",
    "        \n",
    "    new_all_game_situation = np.zeros((len(data), len(data[0]['array_input'][0])))\n",
    "    for i in range(len(data)):\n",
    "        new_all_game_situation[i] = data[i]['array_input'][0]\n",
    "                \n",
    "\n",
    "        \n",
    "        \n",
    "    new_card_to_use = np.zeros((len(data), len(data[0]['gen_my_all_card'][0])))\n",
    "    for i in range(len(data)):\n",
    "        new_card_to_use[i] = data[i]['gen_my_all_card'][0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    new_all_rewards = np.zeros((len(data), 1), dtype=np.dtype('int64'))\n",
    "    for i in range(len(data)):\n",
    "        new_all_rewards[i] = data[i]['reward']\n",
    "    \n",
    "    #new_action_val_array = np.zeros((len(data), len(data[0]['action_val'])))\n",
    "    #for i in range(len(data)):\n",
    "    #    ind = np.argmax(data[i]['action_val'])\n",
    "    #    new_action_val_array[i][ind] = 1\n",
    "    \n",
    "    gen_all_card_second = np.zeros((len(data), len(data[0]['gen_all_card_second'][0])))\n",
    "    for i in range(len(data)):\n",
    "        gen_all_card_second[i] = data[i]['gen_all_card_second'][0]\n",
    "    \n",
    "\n",
    "    card_deck = np.zeros((len(data), len(data[0]['card_deck'][0])))\n",
    "    for i in range(len(data)):\n",
    "        card_deck[i] = data[i]['card_deck'][0]\n",
    "        \n",
    "    new_all_game_situation = np.concatenate([new_all_game_situation, new_card_to_use - gen_all_card_second], axis=1)\n",
    "    return new_all_game_situation, new_all_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = load_data('data_2000.txt')\n",
    "X_train, y_train = load_data('data_4000.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _, y_train, _ = train_test_split(X_test, y_test, test_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = load_data('data_2000.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_big_1, y_train_big_1 = load_data('data_big_4000.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_big_2, y_train_big_2 = load_data('data_big_8000.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_big_3, y_train_big_3 = load_data('data_big_12000.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_big_4, y_train_big_4 = load_data('data_big_16000.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = load_data('data_big_20000.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate([X_train_big_1, X_train_big_2, X_train_big_3, X_train_big_4], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate([y_train_big_1, y_train_big_2, y_train_big_3, y_train_big_4], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate([X_train_big_1], axis=0)\n",
    "y_train = np.concatenate([y_train_big_1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train = X_train_big_1, y_train_big_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test, y_test = X_train_big_2, y_train_big_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84497 samples, validate on 21176 samples\n",
      "Epoch 1/10000\n",
      "84497/84497 [==============================] - 6s 77us/step - loss: 1.3046 - mse: 1.3046 - val_loss: 0.8626 - val_mse: 0.8626\n",
      "Epoch 2/10000\n",
      "84497/84497 [==============================] - 6s 67us/step - loss: 1.0596 - mse: 1.0596 - val_loss: 0.8136 - val_mse: 0.8136\n",
      "Epoch 3/10000\n",
      "84497/84497 [==============================] - 6s 73us/step - loss: 0.9671 - mse: 0.9671 - val_loss: 0.7980 - val_mse: 0.7980\n",
      "Epoch 4/10000\n",
      "84497/84497 [==============================] - 6s 69us/step - loss: 0.9153 - mse: 0.9153 - val_loss: 0.7905 - val_mse: 0.7905\n",
      "Epoch 5/10000\n",
      "84497/84497 [==============================] - 6s 68us/step - loss: 0.8833 - mse: 0.8833 - val_loss: 0.7865 - val_mse: 0.7865\n",
      "Epoch 6/10000\n",
      "84497/84497 [==============================] - 6s 75us/step - loss: 0.8598 - mse: 0.8598 - val_loss: 0.7828 - val_mse: 0.7828\n",
      "Epoch 7/10000\n",
      "84497/84497 [==============================] - 6s 75us/step - loss: 0.8427 - mse: 0.8427 - val_loss: 0.7793 - val_mse: 0.7793\n",
      "Epoch 8/10000\n",
      "84497/84497 [==============================] - 6s 70us/step - loss: 0.8309 - mse: 0.8309 - val_loss: 0.7808 - val_mse: 0.7808\n",
      "Epoch 9/10000\n",
      "84497/84497 [==============================] - 6s 68us/step - loss: 0.8234 - mse: 0.8234 - val_loss: 0.7773 - val_mse: 0.7773\n",
      "Epoch 10/10000\n",
      "84497/84497 [==============================] - 6s 72us/step - loss: 0.8110 - mse: 0.8110 - val_loss: 0.7736 - val_mse: 0.7736\n",
      "Epoch 11/10000\n",
      "84497/84497 [==============================] - 6s 74us/step - loss: 0.8085 - mse: 0.8085 - val_loss: 0.7718 - val_mse: 0.7718\n",
      "Epoch 12/10000\n",
      "84497/84497 [==============================] - 6s 73us/step - loss: 0.8050 - mse: 0.8050 - val_loss: 0.7707 - val_mse: 0.7707\n",
      "Epoch 13/10000\n",
      "84497/84497 [==============================] - 5s 63us/step - loss: 0.7983 - mse: 0.7983 - val_loss: 0.7741 - val_mse: 0.7741\n",
      "Epoch 14/10000\n",
      "84497/84497 [==============================] - 5s 60us/step - loss: 0.7974 - mse: 0.7974 - val_loss: 0.7710 - val_mse: 0.7710\n",
      "Epoch 15/10000\n",
      "84497/84497 [==============================] - 6s 67us/step - loss: 0.7951 - mse: 0.7951 - val_loss: 0.7684 - val_mse: 0.7684\n",
      "Epoch 16/10000\n",
      "84497/84497 [==============================] - 5s 64us/step - loss: 0.7934 - mse: 0.7934 - val_loss: 0.7681 - val_mse: 0.7681\n",
      "Epoch 17/10000\n",
      "84497/84497 [==============================] - 5s 64us/step - loss: 0.7914 - mse: 0.7914 - val_loss: 0.7655 - val_mse: 0.7655\n",
      "Epoch 18/10000\n",
      "84497/84497 [==============================] - 5s 62us/step - loss: 0.7866 - mse: 0.7866 - val_loss: 0.7645 - val_mse: 0.7645\n",
      "Epoch 19/10000\n",
      "84497/84497 [==============================] - 5s 60us/step - loss: 0.7869 - mse: 0.7869 - val_loss: 0.7737 - val_mse: 0.7737\n",
      "Epoch 20/10000\n",
      "84497/84497 [==============================] - 5s 63us/step - loss: 0.7884 - mse: 0.7884 - val_loss: 0.7632 - val_mse: 0.7632\n",
      "Epoch 21/10000\n",
      "84497/84497 [==============================] - 5s 64us/step - loss: 0.7837 - mse: 0.7837 - val_loss: 0.7658 - val_mse: 0.7658\n",
      "Epoch 22/10000\n",
      "84497/84497 [==============================] - 5s 65us/step - loss: 0.7853 - mse: 0.7853 - val_loss: 0.7620 - val_mse: 0.7620\n",
      "Epoch 23/10000\n",
      "84497/84497 [==============================] - 5s 63us/step - loss: 0.7814 - mse: 0.7814 - val_loss: 0.7668 - val_mse: 0.7668\n",
      "Epoch 24/10000\n",
      "84497/84497 [==============================] - 5s 61us/step - loss: 0.7823 - mse: 0.7823 - val_loss: 0.7675 - val_mse: 0.7675\n",
      "Epoch 25/10000\n",
      "84497/84497 [==============================] - 5s 64us/step - loss: 0.7801 - mse: 0.7801 - val_loss: 0.7615 - val_mse: 0.7615\n",
      "Epoch 26/10000\n",
      "84497/84497 [==============================] - 5s 64us/step - loss: 0.7792 - mse: 0.7792 - val_loss: 0.7602 - val_mse: 0.7602\n",
      "Epoch 27/10000\n",
      "84497/84497 [==============================] - 5s 63us/step - loss: 0.7785 - mse: 0.7785 - val_loss: 0.7615 - val_mse: 0.7615\n",
      "Epoch 28/10000\n",
      "84497/84497 [==============================] - 5s 63us/step - loss: 0.7757 - mse: 0.7757 - val_loss: 0.7609 - val_mse: 0.7609\n",
      "Epoch 29/10000\n",
      "84497/84497 [==============================] - 5s 60us/step - loss: 0.7755 - mse: 0.7755 - val_loss: 0.7619 - val_mse: 0.7619\n",
      "Epoch 30/10000\n",
      "84497/84497 [==============================] - 5s 64us/step - loss: 0.7718 - mse: 0.7718 - val_loss: 0.7591 - val_mse: 0.7591\n",
      "Epoch 31/10000\n",
      "84497/84497 [==============================] - 5s 65us/step - loss: 0.7733 - mse: 0.7733 - val_loss: 0.7593 - val_mse: 0.7593\n",
      "Epoch 32/10000\n",
      "84497/84497 [==============================] - 5s 65us/step - loss: 0.7717 - mse: 0.7717 - val_loss: 0.7578 - val_mse: 0.7578\n",
      "Epoch 33/10000\n",
      "84497/84497 [==============================] - 5s 63us/step - loss: 0.7730 - mse: 0.7730 - val_loss: 0.7589 - val_mse: 0.7589\n",
      "Epoch 34/10000\n",
      "84497/84497 [==============================] - 5s 61us/step - loss: 0.7723 - mse: 0.7723 - val_loss: 0.7602 - val_mse: 0.7602\n",
      "Epoch 35/10000\n",
      "84497/84497 [==============================] - 5s 65us/step - loss: 0.7716 - mse: 0.7716 - val_loss: 0.7578 - val_mse: 0.7578\n",
      "Epoch 36/10000\n",
      "84497/84497 [==============================] - 5s 64us/step - loss: 0.7700 - mse: 0.7700 - val_loss: 0.7602 - val_mse: 0.7602\n",
      "Epoch 37/10000\n",
      "84497/84497 [==============================] - 5s 64us/step - loss: 0.7690 - mse: 0.7690 - val_loss: 0.7589 - val_mse: 0.7589\n",
      "Epoch 38/10000\n",
      "84497/84497 [==============================] - 5s 65us/step - loss: 0.7678 - mse: 0.7678 - val_loss: 0.7572 - val_mse: 0.7572\n",
      "Epoch 39/10000\n",
      "84497/84497 [==============================] - 5s 60us/step - loss: 0.7670 - mse: 0.7670 - val_loss: 0.7604 - val_mse: 0.7604\n",
      "Epoch 40/10000\n",
      "84497/84497 [==============================] - 5s 65us/step - loss: 0.7670 - mse: 0.7670 - val_loss: 0.7574 - val_mse: 0.7574\n",
      "Epoch 41/10000\n",
      "84497/84497 [==============================] - 6s 66us/step - loss: 0.7668 - mse: 0.7668 - val_loss: 0.7606 - val_mse: 0.7606\n",
      "Epoch 42/10000\n",
      "84497/84497 [==============================] - 6s 66us/step - loss: 0.7651 - mse: 0.7651 - val_loss: 0.7586 - val_mse: 0.7586\n",
      "Epoch 43/10000\n",
      "84497/84497 [==============================] - 5s 63us/step - loss: 0.7660 - mse: 0.7660 - val_loss: 0.7617 - val_mse: 0.7617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a60cc475f8>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Reshape, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "input = Input(shape=(len(X_train[0]),))\n",
    "bn = BatchNormalization()(input)\n",
    "lr1 = Dense(1024, activation='relu')(bn)\n",
    "do1 = Dropout(0.5)(lr1)\n",
    "#lr2 = Dense(5000, activation='relu')(do1)\n",
    "#do2 = Dropout(0.5)(lr1)\n",
    "#lr3 = Dense(5000, activation='relu')(do2)\n",
    "#do3 = Dropout(0.5)(lr1)\n",
    "#lr4 = Dense(5000, activation='relu')(do3)\n",
    "#do4 = Dropout(0.5)(lr1)\n",
    "#lr5 = Dense(5000, activation='relu')(do4)\n",
    "#do5 = Dropout(0.5)(lr1)\n",
    "#lr6 = Dense(5000, activation='relu')(do5)\n",
    "#do6 = Dropout(0.5)(lr1)\n",
    "output = Dense(1, activation='tan')(do1)\n",
    "\n",
    "model = Model(input, output, name=\"encoder\")\n",
    "\n",
    "\n",
    "opt = SGD(lr=0.01)\n",
    "model.compile(optimizer=opt, loss='mse', metrics=['mse'])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor = 'val_loss', patience = 5)]\n",
    "model.fit(X_train, y_train,\n",
    "                epochs=10000,\n",
    "                shuffle=True,\n",
    "                batch_size=2048,\n",
    "                validation_data=(X_test, y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84497 samples, validate on 21176 samples\n",
      "Epoch 1/10000\n",
      "84497/84497 [==============================] - 5s 59us/step - loss: 0.6798 - mse: 0.8427 - val_loss: 0.6855 - val_mse: 0.8330\n",
      "Epoch 2/10000\n",
      "84497/84497 [==============================] - 5s 61us/step - loss: 0.6791 - mse: 0.8436 - val_loss: 0.6840 - val_mse: 0.8328\n",
      "Epoch 3/10000\n",
      "84497/84497 [==============================] - 5s 64us/step - loss: 0.6780 - mse: 0.8438 - val_loss: 0.6825 - val_mse: 0.8326\n",
      "Epoch 4/10000\n",
      "84497/84497 [==============================] - 5s 64us/step - loss: 0.6767 - mse: 0.8434 - val_loss: 0.6811 - val_mse: 0.8326\n",
      "Epoch 5/10000\n",
      "84497/84497 [==============================] - 5s 63us/step - loss: 0.6733 - mse: 0.8390 - val_loss: 0.6798 - val_mse: 0.8325\n",
      "Epoch 6/10000\n",
      "84497/84497 [==============================] - 5s 64us/step - loss: 0.6747 - mse: 0.8438 - val_loss: 0.6785 - val_mse: 0.8325\n",
      "Epoch 7/10000\n",
      "84497/84497 [==============================] - 5s 61us/step - loss: 0.6710 - mse: 0.8394 - val_loss: 0.6772 - val_mse: 0.8325\n",
      "Epoch 8/10000\n",
      "84497/84497 [==============================] - 5s 64us/step - loss: 0.6706 - mse: 0.8405 - val_loss: 0.6759 - val_mse: 0.8325\n",
      "Epoch 9/10000\n",
      "84497/84497 [==============================] - 5s 65us/step - loss: 0.6690 - mse: 0.8403 - val_loss: 0.6747 - val_mse: 0.8326\n",
      "Epoch 10/10000\n",
      "84497/84497 [==============================] - 5s 65us/step - loss: 0.6689 - mse: 0.8427 - val_loss: 0.6736 - val_mse: 0.8326\n",
      "Epoch 11/10000\n",
      "84497/84497 [==============================] - 5s 64us/step - loss: 0.6675 - mse: 0.8417 - val_loss: 0.6724 - val_mse: 0.8328\n",
      "Epoch 12/10000\n",
      "84497/84497 [==============================] - 5s 60us/step - loss: 0.6665 - mse: 0.8418 - val_loss: 0.6713 - val_mse: 0.8329\n",
      "Epoch 13/10000\n",
      "84497/84497 [==============================] - 5s 63us/step - loss: 0.6637 - mse: 0.8389 - val_loss: 0.6702 - val_mse: 0.8329\n",
      "Epoch 14/10000\n",
      "84497/84497 [==============================] - 5s 64us/step - loss: 0.6630 - mse: 0.8394 - val_loss: 0.6691 - val_mse: 0.8331\n",
      "Epoch 15/10000\n",
      "84497/84497 [==============================] - 6s 65us/step - loss: 0.6640 - mse: 0.8422 - val_loss: 0.6681 - val_mse: 0.8333\n",
      "Epoch 16/10000\n",
      "84497/84497 [==============================] - 5s 64us/step - loss: 0.6609 - mse: 0.8397 - val_loss: 0.6671 - val_mse: 0.8335\n",
      "Epoch 17/10000\n",
      "84497/84497 [==============================] - 6s 69us/step - loss: 0.6593 - mse: 0.8385 - val_loss: 0.6661 - val_mse: 0.8337\n",
      "Epoch 18/10000\n",
      "84497/84497 [==============================] - 5s 61us/step - loss: 0.6581 - mse: 0.8385 - val_loss: 0.6651 - val_mse: 0.8339\n",
      "Epoch 19/10000\n",
      "84497/84497 [==============================] - 5s 65us/step - loss: 0.6579 - mse: 0.8395 - val_loss: 0.6642 - val_mse: 0.8342\n",
      "Epoch 20/10000\n",
      "71680/84497 [========================>.....] - ETA: 0s - loss: 0.6580 - mse: 0.8422"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-249512739959>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                 validation_data=(X_test, y_test), callbacks=callbacks)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "                epochs=10000,\n",
    "                shuffle=True,\n",
    "                batch_size=2048,\n",
    "                validation_data=(X_test, y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5274446227472405\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29196808],\n",
       "       [-0.10801058],\n",
       "       [ 0.5519429 ],\n",
       "       [ 0.00113484],\n",
       "       [-0.38529956],\n",
       "       [-0.3805221 ],\n",
       "       [ 0.14772765],\n",
       "       [-0.95421416],\n",
       "       [-0.71315604],\n",
       "       [ 0.67042935],\n",
       "       [-0.7349194 ],\n",
       "       [ 0.57917446],\n",
       "       [-0.9725838 ],\n",
       "       [-0.48480994],\n",
       "       [ 0.08816356]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = load('critic_loss_0.660.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6973338664458024\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_test, critic.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.038 GB of data: 0.465 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 9, in 0.119s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 9, in 0.120s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 8, in 0.106s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 8, in 0.109s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 8, in 0.106s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, in 0.097s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 9, in 0.125s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 7, in 0.102s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 9, in 0.092s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 8, in 0.108s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 8, in 0.125s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, in 0.105s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 9, in 0.111s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 13, in 0.111s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 11, in 0.119s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 12, in 0.116s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 9, in 0.097s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 11, in 0.107s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, in 0.099s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 13, in 0.113s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 12, in 0.235s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 15, in 0.084s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, in 0.098s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 11, in 0.092s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 13, in 0.116s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, in 0.083s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 13, in 0.093s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, in 0.085s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 13, in 0.097s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 11, in 0.099s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 11, in 0.095s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, in 0.110s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, in 0.093s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 17, in 0.089s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 11, in 0.123s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 14, in 0.096s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 11, in 0.091s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 12, in 0.099s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 15, in 0.109s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, in 0.102s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 14, in 0.220s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 11, in 0.112s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 12, in 0.121s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 12, in 0.090s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, in 0.096s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 13, in 0.088s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 14, in 0.103s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, in 0.099s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 15, in 0.092s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 14, in 0.107s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 11, in 0.091s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 13, in 0.111s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 13, in 0.117s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 16, in 0.100s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 14, in 0.130s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 15, in 0.193s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 14, in 0.144s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 12, in 0.111s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 12, in 0.093s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 11, in 0.101s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 13, in 0.098s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 13, in 0.217s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 15, in 0.090s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 15, in 0.089s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 13, in 0.112s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 14, in 0.096s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 12, in 0.158s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 11, in 0.130s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 11, in 0.165s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 14, in 0.132s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 15, in 0.130s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 12, in 0.136s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 12, in 0.095s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 15, in 0.099s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 14, in 0.118s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 18, in 0.102s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 14, in 0.139s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 13, in 0.099s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 9, in 0.126s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 12, in 0.104s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 12, in 0.127s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 14, in 0.222s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 11, in 0.094s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 13, in 0.107s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 9, in 0.099s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 13, in 0.096s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 13, in 0.101s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 11, in 0.087s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 13, in 0.106s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, in 0.100s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 14, in 0.093s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 14, in 0.093s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, in 0.089s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 11, in 0.105s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 11, in 0.109s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 13, in 0.119s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 13, in 0.094s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 17, in 0.084s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 14, in 0.102s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 11, in 0.110s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, in 0.097s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 12, in 0.096s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, in 0.230s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, in 0.147s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 14, in 0.116s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 11, in 0.100s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 14, in 0.095s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, in 0.092s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 12, in 0.079s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 15, in 0.083s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 12, in 0.082s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 14, in 0.093s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 14, in 0.104s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 19, in 0.106s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 21, in 0.091s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 8, in 0.085s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 15, in 0.096s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 15, in 0.082s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 14, in 0.100s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 11, in 0.081s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 13, in 0.077s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 11, in 0.091s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 19, in 0.090s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 14, in 0.251s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 11, in 0.092s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 15, in 0.095s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 19, in 0.084s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 15, in 0.091s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 18, in 0.090s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 12, in 0.072s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 16, in 0.100s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 11, in 0.088s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 12, in 0.093s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 14, in 0.081s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 15, in 0.112s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 13, in 0.069s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, in 0.098s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 18, in 0.079s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 9, in 0.141s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 12, in 0.082s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 14, in 0.093s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 12, in 0.083s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 16, in 0.094s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 13, in 0.093s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 14, in 0.102s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 19, in 0.206s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 13, in 0.084s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 12, in 0.089s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 13, in 0.078s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 18, in 0.081s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151/200] 1 tree, 31 leaves, max depth = 11, in 0.093s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 9, in 0.090s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 15, in 0.093s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 17, in 0.077s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 14, in 0.115s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 14, in 0.084s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 13, in 0.088s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 12, in 0.080s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 8, in 0.092s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 17, in 0.085s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 13, in 0.084s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 11, in 0.086s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 12, in 0.076s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 14, in 0.092s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 15, in 0.079s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 18, in 0.097s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 16, in 0.082s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 12, in 0.199s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 9, in 0.093s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 12, in 0.082s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 9, in 0.080s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 17, in 0.080s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 14, in 0.086s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 12, in 0.099s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 18, in 0.083s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 13, in 0.116s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 13, in 0.084s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 13, in 0.085s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 14, in 0.078s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 16, in 0.069s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 18, in 0.109s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 14, in 0.084s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 16, in 0.089s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 16, in 0.079s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 14, in 0.095s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 13, in 0.091s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 16, in 0.105s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 15, in 0.097s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 15, in 0.081s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 15, in 0.064s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 13, in 0.191s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 20, in 0.072s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 15, in 0.094s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 12, in 0.095s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 15, in 0.092s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 17, in 0.094s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, in 0.073s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 14, in 0.098s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 11, in 0.067s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 9, in 0.082s\n",
      "Fit 200 trees in 21.424 s, (6200 total leaves)\n",
      "Time spent computing histograms: 13.020s\n",
      "Time spent finding best splits:  1.288s\n",
      "Time spent applying splits:      2.523s\n",
      "Time spent predicting:           0.037s\n",
      "0.735965647108462\n"
     ]
    }
   ],
   "source": [
    "est = HistGradientBoostingRegressor(verbose=2, max_iter=200)\n",
    "est.fit(X_train, y_train.ravel())\n",
    "print(mean_squared_error(y_test, est.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10712602],\n",
       "       [-0.12243053],\n",
       "       [ 0.3452082 ],\n",
       "       [-0.25971276],\n",
       "       [-0.28437054],\n",
       "       [ 0.3338394 ],\n",
       "       [-0.20273483],\n",
       "       [ 0.43285337],\n",
       "       [-0.5641596 ],\n",
       "       [ 0.43943235],\n",
       "       [ 0.4847895 ],\n",
       "       [-0.49727315],\n",
       "       [-0.55646074],\n",
       "       [ 0.5392559 ],\n",
       "       [-0.509521  ],\n",
       "       [ 0.50222296],\n",
       "       [-0.37170887],\n",
       "       [ 0.4034697 ],\n",
       "       [-0.43109402],\n",
       "       [ 0.07978395],\n",
       "       [-0.0818106 ],\n",
       "       [ 0.38821605],\n",
       "       [-0.42126086],\n",
       "       [ 0.59114385],\n",
       "       [-0.65338844],\n",
       "       [ 0.6398108 ],\n",
       "       [-0.6719248 ],\n",
       "       [ 0.5704599 ],\n",
       "       [-0.5946426 ],\n",
       "       [-0.66352934],\n",
       "       [ 0.46705028],\n",
       "       [-0.42759892],\n",
       "       [ 0.07293329],\n",
       "       [-0.10713087],\n",
       "       [ 0.28907755],\n",
       "       [-0.52731377],\n",
       "       [ 0.615381  ],\n",
       "       [-0.6931366 ],\n",
       "       [ 0.49481955],\n",
       "       [-0.28086057],\n",
       "       [ 0.4554372 ],\n",
       "       [-0.49119422],\n",
       "       [ 0.4830594 ],\n",
       "       [-0.5210782 ],\n",
       "       [ 0.4650689 ],\n",
       "       [-0.54870963],\n",
       "       [-0.07819471],\n",
       "       [-0.03163116],\n",
       "       [-0.18463814],\n",
       "       [ 0.2175342 ],\n",
       "       [ 0.29567453],\n",
       "       [ 0.23247889],\n",
       "       [-0.05336551],\n",
       "       [-0.1824653 ],\n",
       "       [ 0.11799767],\n",
       "       [ 0.10826672],\n",
       "       [-0.13337329],\n",
       "       [-0.01949094],\n",
       "       [ 0.02198991],\n",
       "       [-0.05331016],\n",
       "       [ 0.05169209],\n",
       "       [-0.46120945],\n",
       "       [ 0.4261611 ],\n",
       "       [ 0.47308174],\n",
       "       [-0.17736034],\n",
       "       [ 0.379911  ],\n",
       "       [-0.37850294],\n",
       "       [ 0.28111973],\n",
       "       [-0.03274298],\n",
       "       [ 0.2765577 ],\n",
       "       [-0.32302982],\n",
       "       [ 0.4890015 ],\n",
       "       [ 0.52641314],\n",
       "       [ 0.6629064 ],\n",
       "       [-0.57417285],\n",
       "       [ 0.6750897 ],\n",
       "       [-0.6757112 ],\n",
       "       [ 0.78498614],\n",
       "       [-0.7647683 ],\n",
       "       [ 0.7199514 ],\n",
       "       [-0.6992311 ],\n",
       "       [ 0.72480386],\n",
       "       [-0.7628381 ],\n",
       "       [ 0.8207252 ],\n",
       "       [-0.8137142 ],\n",
       "       [ 0.05966464],\n",
       "       [-0.11205821],\n",
       "       [ 0.23742357],\n",
       "       [-0.00093515],\n",
       "       [ 0.07425345],\n",
       "       [-0.07352878],\n",
       "       [ 0.14991441],\n",
       "       [-0.21744142],\n",
       "       [ 0.06181641],\n",
       "       [-0.20941521],\n",
       "       [ 0.20173584],\n",
       "       [-0.04326349],\n",
       "       [-0.03007153],\n",
       "       [ 0.16965818],\n",
       "       [-0.38728613]], dtype=float32)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5789287 ],\n",
       "       [-0.32958326],\n",
       "       [ 0.64002913],\n",
       "       [-0.8431802 ],\n",
       "       [ 0.80426174],\n",
       "       [-0.79008085],\n",
       "       [ 0.91677564],\n",
       "       [-0.8998283 ],\n",
       "       [ 0.98294514],\n",
       "       [-0.9849505 ]], dtype=float32)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21361 samples, validate on 21176 samples\n",
      "Epoch 1/100\n",
      "21361/21361 [==============================] - 1s 52us/step - loss: 1.4354 - val_loss: 0.9443\n",
      "Epoch 2/100\n",
      "21361/21361 [==============================] - 1s 29us/step - loss: 1.2457 - val_loss: 0.8963\n",
      "Epoch 3/100\n",
      "21361/21361 [==============================] - 1s 30us/step - loss: 1.1442 - val_loss: 0.8914\n",
      "Epoch 4/100\n",
      "21361/21361 [==============================] - 1s 31us/step - loss: 1.0637 - val_loss: 0.8629\n",
      "Epoch 5/100\n",
      "21361/21361 [==============================] - 1s 29us/step - loss: 0.9996 - val_loss: 0.8390\n",
      "Epoch 6/100\n",
      "21361/21361 [==============================] - 1s 30us/step - loss: 0.9504 - val_loss: 0.8305\n",
      "Epoch 7/100\n",
      "21361/21361 [==============================] - 1s 29us/step - loss: 0.9178 - val_loss: 0.8241\n",
      "Epoch 8/100\n",
      "21361/21361 [==============================] - 1s 27us/step - loss: 0.8839 - val_loss: 0.8099\n",
      "Epoch 9/100\n",
      "21361/21361 [==============================] - 1s 27us/step - loss: 0.8566 - val_loss: 0.8010\n",
      "Epoch 10/100\n",
      "21361/21361 [==============================] - 1s 27us/step - loss: 0.8278 - val_loss: 0.7912\n",
      "Epoch 11/100\n",
      "21361/21361 [==============================] - 1s 27us/step - loss: 0.8111 - val_loss: 0.7840\n",
      "Epoch 12/100\n",
      "21361/21361 [==============================] - 1s 27us/step - loss: 0.7841 - val_loss: 0.7772\n",
      "Epoch 13/100\n",
      "21361/21361 [==============================] - 1s 29us/step - loss: 0.7713 - val_loss: 0.7716\n",
      "Epoch 14/100\n",
      "21361/21361 [==============================] - 1s 27us/step - loss: 0.7580 - val_loss: 0.7647\n",
      "Epoch 15/100\n",
      "21361/21361 [==============================] - 1s 27us/step - loss: 0.7367 - val_loss: 0.7604\n",
      "Epoch 16/100\n",
      "21361/21361 [==============================] - 1s 28us/step - loss: 0.7202 - val_loss: 0.7570\n",
      "Epoch 17/100\n",
      "21361/21361 [==============================] - 1s 29us/step - loss: 0.7156 - val_loss: 0.7555\n",
      "Epoch 18/100\n",
      "21361/21361 [==============================] - 1s 32us/step - loss: 0.7104 - val_loss: 0.7535\n",
      "Epoch 19/100\n",
      "21361/21361 [==============================] - 1s 29us/step - loss: 0.6952 - val_loss: 0.7526\n",
      "Epoch 20/100\n",
      "21361/21361 [==============================] - 1s 30us/step - loss: 0.6955 - val_loss: 0.7507\n",
      "Epoch 21/100\n",
      "21361/21361 [==============================] - 1s 36us/step - loss: 0.6893 - val_loss: 0.7505\n",
      "Epoch 22/100\n",
      "21361/21361 [==============================] - 1s 34us/step - loss: 0.6818 - val_loss: 0.7501\n",
      "Epoch 23/100\n",
      "21361/21361 [==============================] - 1s 32us/step - loss: 0.6842 - val_loss: 0.7488\n",
      "Epoch 24/100\n",
      "21361/21361 [==============================] - 1s 29us/step - loss: 0.6746 - val_loss: 0.7481\n",
      "Epoch 25/100\n",
      "21361/21361 [==============================] - 1s 33us/step - loss: 0.6734 - val_loss: 0.7486\n",
      "Epoch 26/100\n",
      "21361/21361 [==============================] - 1s 36us/step - loss: 0.6682 - val_loss: 0.7480\n",
      "Epoch 27/100\n",
      "21361/21361 [==============================] - 1s 38us/step - loss: 0.6672 - val_loss: 0.7484\n",
      "Epoch 28/100\n",
      "21361/21361 [==============================] - 1s 35us/step - loss: 0.6605 - val_loss: 0.7481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a30b06eac8>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Reshape, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "input = Input(shape=(220,))\n",
    "bn = BatchNormalization()(input)\n",
    "lr1 = Dense(256, activation='relu')(bn)\n",
    "output = Dense(1, activation='tanh')(lr1)\n",
    "\n",
    "model = Model(input, output)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "callbacks = [EarlyStopping(monitor = 'val_loss', patience = 2)]\n",
    "model.fit(X_train, y_train,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                batch_size=2048,\n",
    "                validation_data=(X_test, y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21361 samples, validate on 21176 samples\n",
      "Epoch 1/100\n",
      "21361/21361 [==============================] - 1s 61us/step - loss: 1.3946 - val_loss: 0.9580\n",
      "Epoch 2/100\n",
      "21361/21361 [==============================] - 1s 45us/step - loss: 1.1548 - val_loss: 0.9123\n",
      "Epoch 3/100\n",
      "21361/21361 [==============================] - 1s 43us/step - loss: 1.0605 - val_loss: 0.9035\n",
      "Epoch 4/100\n",
      "21361/21361 [==============================] - 1s 43us/step - loss: 0.9865 - val_loss: 0.9062\n",
      "Epoch 5/100\n",
      "21361/21361 [==============================] - 1s 43us/step - loss: 0.9460 - val_loss: 0.9068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3093e8358>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Reshape, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "input = Input(shape=(len(X_train[0]),))\n",
    "bn = BatchNormalization()(input)\n",
    "lr1 = Dense(512, activation='tanh')(bn)\n",
    "do1 = Dropout(0.75)(lr1)\n",
    "output = Dense(1, activation='tanh')(do1)\n",
    "\n",
    "model = Model(input, output, name=\"encoder\")\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "callbacks = [EarlyStopping(monitor = 'val_loss', patience = 2)]\n",
    "model.fit(X_train, y_train,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                batch_size=2048,\n",
    "                validation_data=(X_test, y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.9 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84497 samples, validate on 21176 samples\n",
      "Epoch 1/100\n",
      "84497/84497 [==============================] - 3s 36us/step - loss: 1.5549 - val_loss: 0.8481\n",
      "Epoch 2/100\n",
      "84497/84497 [==============================] - 2s 30us/step - loss: 1.3248 - val_loss: 0.8244\n",
      "Epoch 3/100\n",
      "84497/84497 [==============================] - 3s 30us/step - loss: 1.1554 - val_loss: 0.7992\n",
      "Epoch 4/100\n",
      "84497/84497 [==============================] - 2s 26us/step - loss: 1.0136 - val_loss: 0.7617\n",
      "Epoch 5/100\n",
      "84497/84497 [==============================] - 2s 27us/step - loss: 0.8878 - val_loss: 0.7632\n",
      "Epoch 6/100\n",
      "84497/84497 [==============================] - 2s 26us/step - loss: 0.8248 - val_loss: 0.7669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a640e1d080>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Reshape, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "input = Input(shape=(len(X_test[0]),))\n",
    "bn = BatchNormalization()(input)\n",
    "lr1 = Dense(256, activation='relu')(bn)\n",
    "do1 = Dropout(0.5)(lr1)\n",
    "output = Dense(1, activation='tanh')(do1)\n",
    "\n",
    "model = Model(input, output, name=\"encoder\")\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "callbacks = [EarlyStopping(monitor = 'val_loss', patience = 2)]\n",
    "model.fit(X_train, y_train,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                batch_size=2048,\n",
    "                validation_data=(X_test, y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21361 samples, validate on 21176 samples\n",
      "Epoch 1/100\n",
      "21361/21361 [==============================] - 2s 98us/step - loss: 1.2278 - val_loss: 0.8770\n",
      "Epoch 2/100\n",
      "21361/21361 [==============================] - 2s 71us/step - loss: 1.0067 - val_loss: 0.8974\n",
      "Epoch 3/100\n",
      "21361/21361 [==============================] - 2s 72us/step - loss: 0.9129 - val_loss: 0.8832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a302263c18>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Reshape, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "input = Input(shape=(len(X_train[0]),))\n",
    "bn = BatchNormalization()(input)\n",
    "lr1 = Dense(1024, activation='relu')(bn)\n",
    "do1 = Dropout(0.75)(lr1)\n",
    "output = Dense(1, activation='tanh')(do1)\n",
    "\n",
    "model = Model(input, output, name=\"encoder\")\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "callbacks = [EarlyStopping(monitor = 'val_loss', patience = 2)]\n",
    "model.fit(X_train, y_train,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                batch_size=2048,\n",
    "                validation_data=(X_test, y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21361 samples, validate on 21176 samples\n",
      "Epoch 1/100\n",
      "21361/21361 [==============================] - 5s 230us/step - loss: 1.4575 - val_loss: 1.0030\n",
      "Epoch 2/100\n",
      "21361/21361 [==============================] - 4s 191us/step - loss: 1.2463 - val_loss: 0.9524\n",
      "Epoch 3/100\n",
      "21361/21361 [==============================] - 5s 227us/step - loss: 1.1635 - val_loss: 0.8929\n",
      "Epoch 4/100\n",
      "21361/21361 [==============================] - 5s 220us/step - loss: 1.0804 - val_loss: 0.8590\n",
      "Epoch 5/100\n",
      "21361/21361 [==============================] - 5s 217us/step - loss: 1.0148 - val_loss: 0.8416\n",
      "Epoch 6/100\n",
      "21361/21361 [==============================] - 5s 223us/step - loss: 0.9649 - val_loss: 0.8010\n",
      "Epoch 7/100\n",
      "21361/21361 [==============================] - 5s 226us/step - loss: 0.9249 - val_loss: 0.7914\n",
      "Epoch 8/100\n",
      "21361/21361 [==============================] - 5s 214us/step - loss: 0.8740 - val_loss: 0.7867\n",
      "Epoch 9/100\n",
      "21361/21361 [==============================] - 5s 215us/step - loss: 0.8434 - val_loss: 0.8014\n",
      "Epoch 10/100\n",
      "21361/21361 [==============================] - 5s 221us/step - loss: 0.8143 - val_loss: 0.8193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3015e7c88>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Reshape, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "input = Input(shape=(len(X_train[0]),))\n",
    "bn = BatchNormalization()(input)\n",
    "lr1 = Dense(1024, activation='relu')(bn)\n",
    "do1 = Dropout(0.75)(lr1)\n",
    "lr2 = Dense(1024, activation='relu')(do1)\n",
    "do2 = Dropout(0.75)(lr2)\n",
    "output = Dense(1, activation='tanh')(do2)\n",
    "\n",
    "model = Model(input, output, name=\"encoder\")\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "callbacks = [EarlyStopping(monitor = 'val_loss', patience = 2)]\n",
    "model.fit(X_train, y_train,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                batch_size=4096,\n",
    "                validation_data=(X_test, y_test), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_input = Input(shape=(2 + 2 + 6 + 6,))\n",
    "action_input = Input(shape=(34 * 3 * 2,), name='action_input')\n",
    "    \n",
    "bn = concatenate([BatchNormalization()(board_input), action_input], axis=1)\n",
    "lr1 = Dense(256, activation='relu')(bn)\n",
    "value_output = Dense(1, activation='tanh')(lr1)\n",
    "\n",
    "model = Model(inputs=[board_input, action_input], outputs=value_output)\n",
    "    \n",
    "opt = Adam(lr=0.00001)\n",
    "model.compile(loss='mse', optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_1 = X_test[:,:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37., 18., 20., ..., 11.,  6., 14.],\n",
       "       [37., 10., 21., ..., 10.,  2.,  7.],\n",
       "       [33.,  6., 48., ..., 10.,  3., 10.],\n",
       "       ...,\n",
       "       [28., 24., 43., ..., 53.,  4.,  1.],\n",
       "       [28., 17., 43., ..., 45.,  1.,  4.],\n",
       "       [38.,  6., 40., ..., 13., 11., 12.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2 = X_test[:,16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('critic.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8365375673230624\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_test, model.predict([X_test_1, X_test_2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9146242765874205"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8365375673230624**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "#random seed as the birthday of my granp which is in the hospital fighting with cancer\n",
    "#be strong Valdomiro!\n",
    "np.random.seed(10171927)\n",
    "tf.random.set_seed(10171927)\n",
    "\n",
    "#to see how long the notebook lasts to run\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TensorFlow version (expected = 2.0.0):', tf.__version__)\n",
    "print('TensorFlow Probability version (expected = 0.9.0-dev20190912):', tfp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_x, cp_y = X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = cp_x[:10000], cp_y[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bayesian_bcnn_model(input_shape):\n",
    "    \n",
    "    \"\"\"\n",
    "    Here we use tf.keras.Model to use our graph as a Neural Network:\n",
    "    We select our input node as the net input, and the last node as our output (predict node).\n",
    "    Note that our model won't be compiled, as we are usign TF2.0 and will optimize it with\n",
    "    a custom @tf.function for loss and a @tf.function for train_step\n",
    "    Our input parameter is just the input shape, a tuple, for the input layer\n",
    "    \"\"\"\n",
    "    \n",
    "    model_in = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.BatchNormalization()(model_in)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    #x = tf.keras.layers.Activation('relu')(x)\n",
    "    dense_1 = tfp.python.layers.DenseFlipout(128, activation='relu')\n",
    "    x = dense_1(x)\n",
    "    dense_2 = tfp.python.layers.DenseFlipout(1, activation='tanh')\n",
    "    model_out = dense_2(x)  # logits\n",
    "    model = tf.keras.Model(model_in, model_out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def elbo_loss(labels, logits):\n",
    "    #loss_en = tf.nn.softmax_cross_entropy_with_logits(labels, logits)\n",
    "    #loss_kl = tf.keras.losses.KLD(labels, logits)\n",
    "    loss_kl = tf.keras.losses.MSE(labels, logits)\n",
    "    #loss = tf.reduce_mean(tf.add(loss_en, loss_kl))\n",
    "    loss = tf.reduce_mean(loss_kl)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = bcnn(X_train)\n",
    "        loss = elbo_loss(labels, logits)\n",
    "    gradients = tape.gradient(loss, bcnn.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, bcnn.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "#def accuracy(preds, labels):\n",
    "#    return np.mean(np.argmax(preds, axis=1) == np.argmax(labels, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\79672\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_probability\\python\\layers\\util.py:104: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "bcnn = build_bayesian_bcnn_model(X_train.shape[1:])\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_big_1 = keras.utils.to_categorical(y_train_big_1, 2)\n",
    "#y_train_big_2 = keras.utils.to_categorical(y_train_big_2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer batch_normalization is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "tf.Tensor(\n",
      "[[0.99983597]\n",
      " [0.9999991 ]\n",
      " [0.99907553]\n",
      " [0.31383407]\n",
      " [0.99991256]\n",
      " [0.9996051 ]\n",
      " [0.9162453 ]\n",
      " [0.981101  ]\n",
      " [0.9961533 ]\n",
      " [0.9969849 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 0: loss =   1.853, val_loss =   1.834, time:   6.169\n",
      "tf.Tensor(\n",
      "[[ 0.99842376]\n",
      " [ 0.9742869 ]\n",
      " [-0.99999636]\n",
      " [-0.9988516 ]\n",
      " [ 0.18709797]\n",
      " [ 0.99970883]\n",
      " [ 0.9995341 ]\n",
      " [-0.9901253 ]\n",
      " [ 0.43300477]\n",
      " [-0.99998057]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 1: loss =   1.843, val_loss =   1.558, time:   1.359\n",
      "tf.Tensor(\n",
      "[[ 0.9988444 ]\n",
      " [-0.99086   ]\n",
      " [-0.9984841 ]\n",
      " [-0.99867696]\n",
      " [ 0.90062505]\n",
      " [-0.99999976]\n",
      " [-0.9338746 ]\n",
      " [-0.47364184]\n",
      " [-0.99999964]\n",
      " [-0.999591  ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 2: loss =   1.548, val_loss =   1.528, time:   1.400\n",
      "tf.Tensor(\n",
      "[[ 0.9995352 ]\n",
      " [ 0.99904466]\n",
      " [ 0.42600113]\n",
      " [-0.9974677 ]\n",
      " [ 0.9938179 ]\n",
      " [ 0.97894907]\n",
      " [-0.76789963]\n",
      " [ 0.8723901 ]\n",
      " [ 0.99907625]\n",
      " [ 1.        ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 3: loss =   1.436, val_loss =   1.492, time:   1.545\n",
      "tf.Tensor(\n",
      "[[ 0.99999624]\n",
      " [-0.88818157]\n",
      " [ 0.80807257]\n",
      " [-0.8779365 ]\n",
      " [-0.05047657]\n",
      " [-0.9998729 ]\n",
      " [ 0.05514643]\n",
      " [-0.9654542 ]\n",
      " [-0.5299115 ]\n",
      " [ 0.9999997 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 4: loss =   1.492, val_loss =   1.426, time:   1.594\n",
      "tf.Tensor(\n",
      "[[ 0.9990578 ]\n",
      " [ 0.97163117]\n",
      " [-0.99999434]\n",
      " [-0.9989375 ]\n",
      " [-0.9122565 ]\n",
      " [-0.9244073 ]\n",
      " [-0.10883828]\n",
      " [-0.9999994 ]\n",
      " [-0.99285096]\n",
      " [ 0.6456935 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 5: loss =   1.374, val_loss =   1.453, time:   1.627\n",
      "tf.Tensor(\n",
      "[[ 0.9999989 ]\n",
      " [ 0.99975556]\n",
      " [-0.99941707]\n",
      " [-0.9859892 ]\n",
      " [-0.99971294]\n",
      " [-0.99999994]\n",
      " [ 0.677777  ]\n",
      " [-0.9972861 ]\n",
      " [-0.92144006]\n",
      " [ 0.99998546]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 6: loss =   1.389, val_loss =   1.403, time:   1.510\n",
      "tf.Tensor(\n",
      "[[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.99593055]\n",
      " [ 0.04621485]\n",
      " [-0.9666194 ]\n",
      " [-0.97264093]\n",
      " [ 0.9999634 ]\n",
      " [-0.99999756]\n",
      " [ 0.99653417]\n",
      " [ 0.9999939 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 7: loss =   1.362, val_loss =   1.363, time:   1.290\n",
      "tf.Tensor(\n",
      "[[ 1.        ]\n",
      " [ 0.99997354]\n",
      " [ 0.9575141 ]\n",
      " [ 0.43175247]\n",
      " [-0.999582  ]\n",
      " [-0.958284  ]\n",
      " [ 0.9969492 ]\n",
      " [-0.99761987]\n",
      " [ 0.9998575 ]\n",
      " [ 1.        ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 8: loss =   1.349, val_loss =   1.384, time:   1.234\n",
      "tf.Tensor(\n",
      "[[ 1.        ]\n",
      " [ 1.        ]\n",
      " [-0.43896055]\n",
      " [-0.96161836]\n",
      " [-0.5998175 ]\n",
      " [-0.9999923 ]\n",
      " [ 0.8104805 ]\n",
      " [-0.9996616 ]\n",
      " [ 0.9592346 ]\n",
      " [ 0.99999976]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 9: loss =   1.313, val_loss =   1.316, time:   1.196\n",
      "tf.Tensor(\n",
      "[[ 0.9990853 ]\n",
      " [ 0.9999148 ]\n",
      " [-0.9995657 ]\n",
      " [-0.9391764 ]\n",
      " [-0.9920358 ]\n",
      " [-0.9816502 ]\n",
      " [ 0.99087584]\n",
      " [-0.99975306]\n",
      " [-0.6183335 ]\n",
      " [ 1.        ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 10: loss =   1.276, val_loss =   1.311, time:   1.253\n",
      "tf.Tensor(\n",
      "[[ 1.        ]\n",
      " [ 0.99999976]\n",
      " [-0.99999774]\n",
      " [-0.9999836 ]\n",
      " [-0.9999187 ]\n",
      " [ 0.16392401]\n",
      " [ 0.82108426]\n",
      " [-0.9999313 ]\n",
      " [ 0.9693084 ]\n",
      " [ 1.        ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 11: loss =   1.245, val_loss =   1.316, time:   1.250\n",
      "tf.Tensor(\n",
      "[[ 0.9995858 ]\n",
      " [ 0.99994415]\n",
      " [-0.9998294 ]\n",
      " [-0.99928266]\n",
      " [-0.9963184 ]\n",
      " [-0.9819531 ]\n",
      " [ 0.87014484]\n",
      " [-0.9998581 ]\n",
      " [-0.18196383]\n",
      " [ 0.32294312]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 12: loss =   1.250, val_loss =   1.286, time:   1.255\n",
      "tf.Tensor(\n",
      "[[ 0.9999999 ]\n",
      " [ 0.9999995 ]\n",
      " [-0.9971466 ]\n",
      " [-0.9376122 ]\n",
      " [-0.9995824 ]\n",
      " [-0.99871564]\n",
      " [ 0.53611666]\n",
      " [-0.9999775 ]\n",
      " [ 0.9994125 ]\n",
      " [ 1.        ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 13: loss =   1.270, val_loss =   1.267, time:   1.281\n",
      "tf.Tensor(\n",
      "[[ 1.        ]\n",
      " [ 0.99999994]\n",
      " [ 0.27347597]\n",
      " [-0.99494666]\n",
      " [-0.9920739 ]\n",
      " [-0.4495598 ]\n",
      " [ 0.9999415 ]\n",
      " [-0.99996686]\n",
      " [ 0.90825295]\n",
      " [ 0.99992836]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 14: loss =   1.249, val_loss =   1.261, time:   1.441\n",
      "tf.Tensor(\n",
      "[[ 0.9999988 ]\n",
      " [ 0.9998859 ]\n",
      " [-0.99956644]\n",
      " [-0.9993387 ]\n",
      " [-0.7744286 ]\n",
      " [-0.99998957]\n",
      " [ 0.9994939 ]\n",
      " [-0.9998686 ]\n",
      " [ 0.07543118]\n",
      " [ 1.        ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 15: loss =   1.199, val_loss =   1.267, time:   1.340\n",
      "tf.Tensor(\n",
      "[[ 1.        ]\n",
      " [ 0.99999976]\n",
      " [-0.9999138 ]\n",
      " [-0.9970957 ]\n",
      " [-0.9999491 ]\n",
      " [-0.9999999 ]\n",
      " [ 0.9517394 ]\n",
      " [-0.99987936]\n",
      " [ 0.7746911 ]\n",
      " [-0.29382604]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 16: loss =   1.195, val_loss =   1.255, time:   1.263\n",
      "tf.Tensor(\n",
      "[[ 0.999994  ]\n",
      " [ 0.9999712 ]\n",
      " [-0.99997985]\n",
      " [-0.9056725 ]\n",
      " [-0.99841547]\n",
      " [-0.67917025]\n",
      " [ 0.81851524]\n",
      " [-0.99976146]\n",
      " [-0.9994651 ]\n",
      " [ 1.        ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 17: loss =   1.201, val_loss =   1.262, time:   1.273\n",
      "tf.Tensor(\n",
      "[[ 1.        ]\n",
      " [ 1.        ]\n",
      " [ 0.76877534]\n",
      " [-0.6508912 ]\n",
      " [-0.99713594]\n",
      " [-0.40670303]\n",
      " [ 0.9999589 ]\n",
      " [-0.99993026]\n",
      " [ 0.96211743]\n",
      " [ 0.9417706 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 18: loss =   1.173, val_loss =   1.250, time:   1.250\n",
      "tf.Tensor(\n",
      "[[ 0.9997449 ]\n",
      " [ 0.99996835]\n",
      " [ 0.6897553 ]\n",
      " [-0.9986558 ]\n",
      " [-0.99411863]\n",
      " [-0.9990596 ]\n",
      " [ 0.99844337]\n",
      " [-0.9999733 ]\n",
      " [ 0.14219628]\n",
      " [ 0.5299728 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 19: loss =   1.200, val_loss =   1.207, time:   1.254\n",
      "tf.Tensor(\n",
      "[[ 0.9999999 ]\n",
      " [ 0.99853003]\n",
      " [ 0.5564825 ]\n",
      " [-0.99513376]\n",
      " [-0.97207534]\n",
      " [-0.90009874]\n",
      " [ 0.9957829 ]\n",
      " [-0.999939  ]\n",
      " [ 0.9626347 ]\n",
      " [ 0.9999998 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 20: loss =   1.164, val_loss =   1.225, time:   1.274\n",
      "tf.Tensor(\n",
      "[[ 0.99999976]\n",
      " [ 0.999483  ]\n",
      " [-0.99987906]\n",
      " [-0.51691383]\n",
      " [-0.99769497]\n",
      " [-0.99994475]\n",
      " [ 0.96250457]\n",
      " [-0.99997306]\n",
      " [-0.5096805 ]\n",
      " [ 0.9998362 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 21: loss =   1.167, val_loss =   1.181, time:   1.276\n",
      "tf.Tensor(\n",
      "[[ 0.98632526]\n",
      " [ 0.9909052 ]\n",
      " [-0.5639652 ]\n",
      " [-0.69170415]\n",
      " [-0.99538106]\n",
      " [-0.99980885]\n",
      " [ 0.9999599 ]\n",
      " [-0.99967945]\n",
      " [ 0.44980085]\n",
      " [ 0.99325573]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 22: loss =   1.127, val_loss =   1.196, time:   1.208\n",
      "tf.Tensor(\n",
      "[[ 0.9989995 ]\n",
      " [ 0.998108  ]\n",
      " [ 0.05384424]\n",
      " [-0.9878862 ]\n",
      " [-0.09307741]\n",
      " [-0.999983  ]\n",
      " [ 0.9924511 ]\n",
      " [-0.9993243 ]\n",
      " [ 0.41855362]\n",
      " [ 0.99996346]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 23: loss =   1.138, val_loss =   1.177, time:   1.193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.9999989 ]\n",
      " [ 0.9934065 ]\n",
      " [-0.54466623]\n",
      " [ 0.4654407 ]\n",
      " [ 0.2010665 ]\n",
      " [-0.9363418 ]\n",
      " [ 0.9181771 ]\n",
      " [-0.9969605 ]\n",
      " [-0.97059804]\n",
      " [ 0.99999255]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 24: loss =   1.103, val_loss =   1.159, time:   1.157\n",
      "tf.Tensor(\n",
      "[[ 1.        ]\n",
      " [ 0.96054405]\n",
      " [ 0.777756  ]\n",
      " [-0.98774415]\n",
      " [-0.9829916 ]\n",
      " [-0.9873745 ]\n",
      " [ 0.9997976 ]\n",
      " [-0.9737393 ]\n",
      " [-0.99983025]\n",
      " [ 0.9987641 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 25: loss =   1.126, val_loss =   1.134, time:   1.035\n",
      "tf.Tensor(\n",
      "[[ 0.9998997 ]\n",
      " [ 0.9970043 ]\n",
      " [-0.6706757 ]\n",
      " [-0.97228193]\n",
      " [-0.8586792 ]\n",
      " [-0.9968167 ]\n",
      " [ 0.97371364]\n",
      " [-0.9830823 ]\n",
      " [-0.9747187 ]\n",
      " [ 0.99992305]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 26: loss =   1.113, val_loss =   1.131, time:   1.060\n",
      "tf.Tensor(\n",
      "[[ 0.99991935]\n",
      " [ 0.9970339 ]\n",
      " [-0.67523956]\n",
      " [-0.40590194]\n",
      " [-0.99096704]\n",
      " [ 0.7783321 ]\n",
      " [ 0.97327197]\n",
      " [-0.99930435]\n",
      " [-0.9244281 ]\n",
      " [-0.7384589 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 27: loss =   1.068, val_loss =   1.129, time:   1.175\n",
      "tf.Tensor(\n",
      "[[ 0.99976075]\n",
      " [ 0.7864374 ]\n",
      " [-0.8269962 ]\n",
      " [-0.8556115 ]\n",
      " [-0.6661383 ]\n",
      " [-0.98550236]\n",
      " [ 0.97347456]\n",
      " [-0.97753435]\n",
      " [-0.9457271 ]\n",
      " [ 0.9999989 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 28: loss =   1.074, val_loss =   1.117, time:   1.182\n",
      "tf.Tensor(\n",
      "[[ 0.99998367]\n",
      " [ 0.9944088 ]\n",
      " [-0.9991788 ]\n",
      " [-0.97317475]\n",
      " [-0.9492128 ]\n",
      " [-0.22390163]\n",
      " [ 0.9638491 ]\n",
      " [-0.98890823]\n",
      " [-0.99012434]\n",
      " [ 0.9999989 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 29: loss =   1.047, val_loss =   1.121, time:   1.203\n",
      "tf.Tensor(\n",
      "[[ 0.9988801 ]\n",
      " [ 0.98854744]\n",
      " [-0.99604416]\n",
      " [ 0.82360864]\n",
      " [-0.693205  ]\n",
      " [-0.9992228 ]\n",
      " [ 0.9832633 ]\n",
      " [-0.99826103]\n",
      " [-0.86206883]\n",
      " [ 0.9999986 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 30: loss =   1.030, val_loss =   1.103, time:   1.321\n",
      "tf.Tensor(\n",
      "[[ 0.9999923 ]\n",
      " [ 0.99968034]\n",
      " [ 0.45953166]\n",
      " [ 0.01030373]\n",
      " [-0.730018  ]\n",
      " [-0.9999465 ]\n",
      " [ 0.7889489 ]\n",
      " [-0.99958485]\n",
      " [-0.01694833]\n",
      " [ 0.9999818 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 31: loss =   0.985, val_loss =   1.072, time:   1.380\n",
      "tf.Tensor(\n",
      "[[ 0.99896336]\n",
      " [ 0.9381611 ]\n",
      " [-0.23665056]\n",
      " [ 0.30274433]\n",
      " [ 0.1794686 ]\n",
      " [ 0.99668556]\n",
      " [ 0.5791569 ]\n",
      " [-0.97685516]\n",
      " [-0.9948093 ]\n",
      " [-0.16260691]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 32: loss =   0.984, val_loss =   1.037, time:   1.271\n",
      "tf.Tensor(\n",
      "[[ 0.99936026]\n",
      " [ 0.9676239 ]\n",
      " [-0.41135415]\n",
      " [-0.98843294]\n",
      " [-0.2783673 ]\n",
      " [-0.99387616]\n",
      " [ 0.84740144]\n",
      " [-0.9973424 ]\n",
      " [-0.9890226 ]\n",
      " [ 0.99990773]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 33: loss =   1.004, val_loss =   1.006, time:   1.273\n",
      "tf.Tensor(\n",
      "[[ 0.5537977 ]\n",
      " [ 0.8869464 ]\n",
      " [ 0.68797   ]\n",
      " [ 0.61729497]\n",
      " [-0.86400867]\n",
      " [-0.9650505 ]\n",
      " [ 0.7194866 ]\n",
      " [-0.95026785]\n",
      " [-0.8714339 ]\n",
      " [ 0.9486893 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 34: loss =   0.957, val_loss =   0.999, time:   1.246\n",
      "tf.Tensor(\n",
      "[[ 0.9819803 ]\n",
      " [ 0.9617373 ]\n",
      " [-0.85177743]\n",
      " [ 0.01362978]\n",
      " [-0.6918393 ]\n",
      " [-0.6437448 ]\n",
      " [ 0.95864224]\n",
      " [-0.988126  ]\n",
      " [-0.992463  ]\n",
      " [ 0.99563444]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 35: loss =   0.958, val_loss =   0.985, time:   1.262\n",
      "tf.Tensor(\n",
      "[[ 0.99662536]\n",
      " [ 0.9930779 ]\n",
      " [-0.6920103 ]\n",
      " [-0.8120147 ]\n",
      " [-0.04002214]\n",
      " [ 0.9838403 ]\n",
      " [ 0.26064864]\n",
      " [-0.63206285]\n",
      " [-0.4802987 ]\n",
      " [ 0.99763113]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 36: loss =   0.962, val_loss =   0.993, time:   1.259\n",
      "tf.Tensor(\n",
      "[[ 0.7333878 ]\n",
      " [ 0.7019525 ]\n",
      " [-0.8907512 ]\n",
      " [-0.9583813 ]\n",
      " [ 0.15908378]\n",
      " [-0.9637635 ]\n",
      " [ 0.44539043]\n",
      " [-0.9820075 ]\n",
      " [-0.9625415 ]\n",
      " [ 0.9915122 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 37: loss =   0.928, val_loss =   0.954, time:   1.254\n",
      "tf.Tensor(\n",
      "[[ 0.31211028]\n",
      " [ 0.75810575]\n",
      " [ 0.10268354]\n",
      " [-0.47687942]\n",
      " [-0.41619042]\n",
      " [ 0.31955025]\n",
      " [ 0.48141462]\n",
      " [-0.7827617 ]\n",
      " [-0.8728596 ]\n",
      " [ 0.990793  ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 38: loss =   0.922, val_loss =   0.942, time:   1.259\n",
      "tf.Tensor(\n",
      "[[ 0.91651154]\n",
      " [ 0.93088317]\n",
      " [ 0.17058203]\n",
      " [-0.7055163 ]\n",
      " [ 0.01206345]\n",
      " [-0.85370576]\n",
      " [-0.25907892]\n",
      " [-0.8448537 ]\n",
      " [-0.7836586 ]\n",
      " [ 0.9180161 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 39: loss =   0.924, val_loss =   0.932, time:   1.251\n",
      "tf.Tensor(\n",
      "[[ 0.9837075 ]\n",
      " [ 0.8544764 ]\n",
      " [ 0.26379988]\n",
      " [ 0.09510023]\n",
      " [-0.25247675]\n",
      " [-0.5786627 ]\n",
      " [ 0.95584065]\n",
      " [-0.4453227 ]\n",
      " [-0.76996773]\n",
      " [ 0.8507258 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 40: loss =   0.879, val_loss =   0.912, time:   1.192\n",
      "tf.Tensor(\n",
      "[[ 0.61334944]\n",
      " [ 0.7834411 ]\n",
      " [ 0.7300723 ]\n",
      " [-0.26519996]\n",
      " [-0.38226852]\n",
      " [ 0.66909015]\n",
      " [ 0.39798188]\n",
      " [-0.604327  ]\n",
      " [ 0.84741443]\n",
      " [ 0.99781096]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 41: loss =   0.857, val_loss =   0.929, time:   1.155\n",
      "tf.Tensor(\n",
      "[[ 0.7229763 ]\n",
      " [ 0.49861246]\n",
      " [-0.6378373 ]\n",
      " [ 0.80780804]\n",
      " [-0.02719508]\n",
      " [-0.42228696]\n",
      " [ 0.23620537]\n",
      " [-0.2954291 ]\n",
      " [-0.9868974 ]\n",
      " [ 0.99641967]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 42: loss =   0.876, val_loss =   0.904, time:   1.155\n",
      "tf.Tensor(\n",
      "[[ 0.71296453]\n",
      " [ 0.494612  ]\n",
      " [-0.6594655 ]\n",
      " [-0.68560165]\n",
      " [ 0.16878223]\n",
      " [-0.7717252 ]\n",
      " [ 0.25352722]\n",
      " [-0.8038957 ]\n",
      " [-0.8988336 ]\n",
      " [ 0.6940083 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 43: loss =   0.857, val_loss =   0.886, time:   1.078\n",
      "tf.Tensor(\n",
      "[[ 0.83614975]\n",
      " [ 0.16318525]\n",
      " [-0.5056039 ]\n",
      " [-0.34671536]\n",
      " [-0.14332478]\n",
      " [ 0.15057407]\n",
      " [ 0.15699063]\n",
      " [-0.8070711 ]\n",
      " [ 0.08035405]\n",
      " [ 0.99196154]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 44: loss =   0.848, val_loss =   0.887, time:   1.296\n",
      "tf.Tensor(\n",
      "[[ 0.7052384 ]\n",
      " [ 0.33367324]\n",
      " [-0.34905282]\n",
      " [-0.43888417]\n",
      " [ 0.0147119 ]\n",
      " [-0.9393319 ]\n",
      " [ 0.07862508]\n",
      " [-0.9472793 ]\n",
      " [ 0.332138  ]\n",
      " [-0.46061528]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 45: loss =   0.826, val_loss =   0.880, time:   1.235\n",
      "tf.Tensor(\n",
      "[[ 0.68350494]\n",
      " [-0.17510018]\n",
      " [-0.45692736]\n",
      " [ 0.17981322]\n",
      " [ 0.13089436]\n",
      " [ 0.01908456]\n",
      " [ 0.1317421 ]\n",
      " [-0.78327626]\n",
      " [-0.9580939 ]\n",
      " [ 0.193769  ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 46: loss =   0.843, val_loss =   0.882, time:   1.368\n",
      "tf.Tensor(\n",
      "[[ 0.33926478]\n",
      " [-0.14829682]\n",
      " [ 0.5104664 ]\n",
      " [-0.15099005]\n",
      " [ 0.06735287]\n",
      " [-0.1535654 ]\n",
      " [ 0.44697422]\n",
      " [-0.5757037 ]\n",
      " [-0.4347408 ]\n",
      " [ 0.81170344]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 47: loss =   0.831, val_loss =   0.878, time:   1.545\n",
      "tf.Tensor(\n",
      "[[ 0.6037256 ]\n",
      " [ 0.29018074]\n",
      " [-0.52156943]\n",
      " [ 0.12556712]\n",
      " [-0.01622826]\n",
      " [ 0.00661869]\n",
      " [ 0.11082897]\n",
      " [-0.7408782 ]\n",
      " [-0.47271425]\n",
      " [ 0.9763996 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 48: loss =   0.833, val_loss =   0.852, time:   1.466\n",
      "tf.Tensor(\n",
      "[[ 0.68664235]\n",
      " [ 0.5399348 ]\n",
      " [-0.19508946]\n",
      " [ 0.23401853]\n",
      " [ 0.1371088 ]\n",
      " [-0.316166  ]\n",
      " [ 0.51386094]\n",
      " [-0.5877263 ]\n",
      " [-0.86797625]\n",
      " [ 0.5850975 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 49: loss =   0.809, val_loss =   0.870, time:   1.463\n",
      "tf.Tensor(\n",
      "[[ 0.23226652]\n",
      " [ 0.6211179 ]\n",
      " [-0.30741557]\n",
      " [-0.3533935 ]\n",
      " [ 0.09365752]\n",
      " [-0.3981564 ]\n",
      " [ 0.3191585 ]\n",
      " [-0.37845707]\n",
      " [-0.10943935]\n",
      " [ 0.93293947]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 50: loss =   0.840, val_loss =   0.861, time:   1.256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.73727643]\n",
      " [ 0.7450168 ]\n",
      " [-0.30071446]\n",
      " [-0.02155814]\n",
      " [-0.08213896]\n",
      " [-0.5444006 ]\n",
      " [ 0.54316854]\n",
      " [-0.85326576]\n",
      " [-0.47728252]\n",
      " [ 0.4881586 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 51: loss =   0.813, val_loss =   0.862, time:   1.256\n",
      "tf.Tensor(\n",
      "[[ 0.8099113 ]\n",
      " [ 0.4924748 ]\n",
      " [-0.59090716]\n",
      " [-0.5130276 ]\n",
      " [-0.5840848 ]\n",
      " [-0.606215  ]\n",
      " [ 0.67696446]\n",
      " [-0.92513025]\n",
      " [-0.96689874]\n",
      " [ 0.7486763 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 52: loss =   0.807, val_loss =   0.879, time:   1.235\n",
      "tf.Tensor(\n",
      "[[ 0.30446967]\n",
      " [ 0.5017291 ]\n",
      " [-0.6633931 ]\n",
      " [-0.47156236]\n",
      " [-0.0795053 ]\n",
      " [-0.859576  ]\n",
      " [ 0.34515885]\n",
      " [-0.9346589 ]\n",
      " [-0.9595519 ]\n",
      " [ 0.7000551 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 53: loss =   0.819, val_loss =   0.861, time:   1.249\n",
      "tf.Tensor(\n",
      "[[ 0.83338004]\n",
      " [ 0.75809765]\n",
      " [-0.5266529 ]\n",
      " [-0.2764414 ]\n",
      " [-0.22579408]\n",
      " [-0.55515176]\n",
      " [ 0.7306602 ]\n",
      " [-0.6878354 ]\n",
      " [-0.7067135 ]\n",
      " [ 0.8020761 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 54: loss =   0.824, val_loss =   0.872, time:   1.283\n",
      "tf.Tensor(\n",
      "[[ 0.8150866 ]\n",
      " [-0.00593684]\n",
      " [-0.14233667]\n",
      " [ 0.1273915 ]\n",
      " [-0.04328233]\n",
      " [-0.84495896]\n",
      " [ 0.61763436]\n",
      " [-0.58121806]\n",
      " [-0.9227144 ]\n",
      " [ 0.64136636]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 55: loss =   0.804, val_loss =   0.869, time:   1.251\n",
      "tf.Tensor(\n",
      "[[ 0.9695914 ]\n",
      " [ 0.74486935]\n",
      " [ 0.43486118]\n",
      " [-0.10697595]\n",
      " [-0.27355376]\n",
      " [-0.7417138 ]\n",
      " [ 0.6389251 ]\n",
      " [-0.94717765]\n",
      " [-0.5208276 ]\n",
      " [ 0.99734896]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 56: loss =   0.816, val_loss =   0.865, time:   1.270\n",
      "tf.Tensor(\n",
      "[[ 0.87887436]\n",
      " [ 0.33282658]\n",
      " [ 0.04333957]\n",
      " [ 0.21425116]\n",
      " [-0.22605053]\n",
      " [-0.15287194]\n",
      " [ 0.33274072]\n",
      " [-0.91471356]\n",
      " [-0.78776616]\n",
      " [ 0.9213535 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 57: loss =   0.800, val_loss =   0.857, time:   1.253\n",
      "tf.Tensor(\n",
      "[[ 0.54433054]\n",
      " [ 0.3267877 ]\n",
      " [-0.16279668]\n",
      " [-0.58404446]\n",
      " [-0.07990351]\n",
      " [-0.6861441 ]\n",
      " [ 0.36792877]\n",
      " [-0.7863302 ]\n",
      " [-0.07980289]\n",
      " [ 0.8910802 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 58: loss =   0.802, val_loss =   0.848, time:   1.203\n",
      "tf.Tensor(\n",
      "[[ 0.29705763]\n",
      " [ 0.10027149]\n",
      " [-0.92992955]\n",
      " [-0.38011983]\n",
      " [-0.6464878 ]\n",
      " [-0.9056505 ]\n",
      " [ 0.08292997]\n",
      " [-0.7695232 ]\n",
      " [ 0.10139931]\n",
      " [ 0.94492996]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 59: loss =   0.786, val_loss =   0.860, time:   1.191\n",
      "tf.Tensor(\n",
      "[[ 0.42303076]\n",
      " [ 0.72328407]\n",
      " [ 0.176627  ]\n",
      " [ 0.15536188]\n",
      " [-0.25434917]\n",
      " [-0.5290181 ]\n",
      " [ 0.24928704]\n",
      " [-0.8541787 ]\n",
      " [-0.9046333 ]\n",
      " [ 0.97621703]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 60: loss =   0.813, val_loss =   0.839, time:   1.114\n",
      "tf.Tensor(\n",
      "[[ 0.8940421 ]\n",
      " [ 0.90048224]\n",
      " [ 0.380295  ]\n",
      " [ 0.13828847]\n",
      " [-0.0762957 ]\n",
      " [ 0.20436184]\n",
      " [ 0.52787864]\n",
      " [-0.6190679 ]\n",
      " [-0.2919294 ]\n",
      " [ 0.9525939 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 61: loss =   0.783, val_loss =   0.842, time:   1.050\n",
      "tf.Tensor(\n",
      "[[ 0.7914513 ]\n",
      " [ 0.35220414]\n",
      " [-0.38553923]\n",
      " [-0.28079927]\n",
      " [-0.29272306]\n",
      " [-0.05584709]\n",
      " [ 0.49080488]\n",
      " [-0.71846825]\n",
      " [-0.8591674 ]\n",
      " [ 0.98703796]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 62: loss =   0.778, val_loss =   0.848, time:   1.204\n",
      "tf.Tensor(\n",
      "[[ 0.8011091 ]\n",
      " [ 0.7851302 ]\n",
      " [-0.34209684]\n",
      " [-0.2849587 ]\n",
      " [-0.1885518 ]\n",
      " [-0.39759496]\n",
      " [ 0.6381018 ]\n",
      " [-0.69389945]\n",
      " [-0.8764131 ]\n",
      " [ 0.92039496]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 63: loss =   0.792, val_loss =   0.842, time:   1.179\n",
      "tf.Tensor(\n",
      "[[ 0.9502058 ]\n",
      " [ 0.7918489 ]\n",
      " [ 0.19955312]\n",
      " [-0.13038954]\n",
      " [-0.11202466]\n",
      " [ 0.36235133]\n",
      " [ 0.48834288]\n",
      " [-0.86464137]\n",
      " [-0.00653065]\n",
      " [ 0.97347224]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 64: loss =   0.768, val_loss =   0.842, time:   1.228\n",
      "tf.Tensor(\n",
      "[[ 0.41848177]\n",
      " [ 0.7243843 ]\n",
      " [-0.3343781 ]\n",
      " [ 0.0045611 ]\n",
      " [-0.1878906 ]\n",
      " [-0.99283594]\n",
      " [ 0.5128659 ]\n",
      " [-0.93637323]\n",
      " [-0.52106327]\n",
      " [ 0.9495946 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 65: loss =   0.779, val_loss =   0.845, time:   1.287\n",
      "tf.Tensor(\n",
      "[[ 0.8662667 ]\n",
      " [ 0.5662065 ]\n",
      " [ 0.03991833]\n",
      " [-0.19537485]\n",
      " [-0.2955481 ]\n",
      " [-0.6771175 ]\n",
      " [ 0.53552604]\n",
      " [-0.872905  ]\n",
      " [-0.67250115]\n",
      " [ 0.9301266 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 66: loss =   0.774, val_loss =   0.839, time:   1.243\n",
      "tf.Tensor(\n",
      "[[ 0.73940843]\n",
      " [ 0.69738334]\n",
      " [ 0.69985163]\n",
      " [ 0.36800274]\n",
      " [-0.12153803]\n",
      " [-0.22165646]\n",
      " [ 0.6521851 ]\n",
      " [-0.87467355]\n",
      " [-0.70510614]\n",
      " [ 0.9750818 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 67: loss =   0.767, val_loss =   0.823, time:   1.280\n",
      "tf.Tensor(\n",
      "[[ 0.47198284]\n",
      " [ 0.6533922 ]\n",
      " [ 0.11035802]\n",
      " [ 0.35303006]\n",
      " [-0.48248142]\n",
      " [-0.8123445 ]\n",
      " [ 0.34471038]\n",
      " [-0.927235  ]\n",
      " [-0.72860706]\n",
      " [ 0.85476905]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 68: loss =   0.774, val_loss =   0.837, time:   1.257\n",
      "tf.Tensor(\n",
      "[[ 0.67854756]\n",
      " [ 0.36988485]\n",
      " [ 0.30017284]\n",
      " [-0.23235004]\n",
      " [-0.12123603]\n",
      " [-0.16841598]\n",
      " [ 0.6493578 ]\n",
      " [-0.8425013 ]\n",
      " [-0.6223412 ]\n",
      " [ 0.97504926]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 69: loss =   0.770, val_loss =   0.834, time:   1.265\n",
      "tf.Tensor(\n",
      "[[ 0.8158816 ]\n",
      " [ 0.02233822]\n",
      " [-0.5583328 ]\n",
      " [ 0.29404724]\n",
      " [-0.4755118 ]\n",
      " [-0.41529685]\n",
      " [ 0.4723889 ]\n",
      " [-0.82840765]\n",
      " [-0.83932227]\n",
      " [ 0.66291225]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 70: loss =   0.758, val_loss =   0.819, time:   1.306\n",
      "tf.Tensor(\n",
      "[[ 0.79749215]\n",
      " [ 0.5222332 ]\n",
      " [ 0.03651365]\n",
      " [-0.10984279]\n",
      " [-0.36823824]\n",
      " [-0.14333573]\n",
      " [ 0.46247682]\n",
      " [-0.85357434]\n",
      " [-0.20019026]\n",
      " [ 0.97835845]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 71: loss =   0.762, val_loss =   0.835, time:   1.294\n",
      "tf.Tensor(\n",
      "[[ 0.80077493]\n",
      " [ 0.28344223]\n",
      " [ 0.6826738 ]\n",
      " [-0.05552973]\n",
      " [-0.07658519]\n",
      " [-0.43629095]\n",
      " [ 0.34428036]\n",
      " [-0.9259001 ]\n",
      " [-0.39628336]\n",
      " [ 0.87788796]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 72: loss =   0.765, val_loss =   0.830, time:   1.224\n",
      "tf.Tensor(\n",
      "[[ 0.7694544 ]\n",
      " [ 0.60140103]\n",
      " [-0.58070594]\n",
      " [ 0.11841238]\n",
      " [-0.19314773]\n",
      " [-0.37766698]\n",
      " [ 0.6519109 ]\n",
      " [-0.72401077]\n",
      " [-0.62396294]\n",
      " [ 0.96212256]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 73: loss =   0.777, val_loss =   0.825, time:   1.235\n",
      "tf.Tensor(\n",
      "[[ 0.68041193]\n",
      " [ 0.84551173]\n",
      " [ 0.4325454 ]\n",
      " [ 0.02063299]\n",
      " [-0.11173155]\n",
      " [-0.46847758]\n",
      " [ 0.4892526 ]\n",
      " [-0.94105875]\n",
      " [ 0.2451723 ]\n",
      " [ 0.90501904]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 74: loss =   0.739, val_loss =   0.834, time:   1.247\n",
      "tf.Tensor(\n",
      "[[ 0.8598101 ]\n",
      " [ 0.28357452]\n",
      " [ 0.11280107]\n",
      " [-0.50276494]\n",
      " [-0.38406312]\n",
      " [-0.6650915 ]\n",
      " [ 0.5742676 ]\n",
      " [-0.91530615]\n",
      " [-0.72290087]\n",
      " [ 0.92543393]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 75: loss =   0.761, val_loss =   0.821, time:   1.195\n",
      "tf.Tensor(\n",
      "[[ 0.9487025 ]\n",
      " [ 0.61566144]\n",
      " [ 0.5942155 ]\n",
      " [-0.50329906]\n",
      " [-0.02497309]\n",
      " [-0.8093489 ]\n",
      " [ 0.38640204]\n",
      " [-0.97207624]\n",
      " [-0.5912348 ]\n",
      " [ 0.9886012 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 76: loss =   0.751, val_loss =   0.835, time:   1.200\n",
      "tf.Tensor(\n",
      "[[ 0.90479445]\n",
      " [ 0.4628301 ]\n",
      " [-0.24809846]\n",
      " [ 0.09079421]\n",
      " [-0.12796864]\n",
      " [ 0.6860072 ]\n",
      " [ 0.34534207]\n",
      " [-0.94663984]\n",
      " [-0.9630724 ]\n",
      " [ 0.97886693]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 77: loss =   0.761, val_loss =   0.822, time:   1.188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.85246736]\n",
      " [ 0.6061873 ]\n",
      " [ 0.02987074]\n",
      " [-0.39426684]\n",
      " [-0.31889716]\n",
      " [-0.56150985]\n",
      " [ 0.5348409 ]\n",
      " [-0.9641187 ]\n",
      " [ 0.08328824]\n",
      " [ 0.9853317 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 78: loss =   0.761, val_loss =   0.823, time:   1.303\n",
      "tf.Tensor(\n",
      "[[ 0.85331994]\n",
      " [ 0.6623335 ]\n",
      " [ 0.15209658]\n",
      " [ 0.38062465]\n",
      " [-0.08191635]\n",
      " [ 0.31146675]\n",
      " [ 0.6399118 ]\n",
      " [-0.8268905 ]\n",
      " [ 0.24549723]\n",
      " [ 0.99382347]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 79: loss =   0.747, val_loss =   0.828, time:   1.131\n",
      "tf.Tensor(\n",
      "[[ 0.87770003]\n",
      " [ 0.6341458 ]\n",
      " [-0.0361998 ]\n",
      " [ 0.3349615 ]\n",
      " [ 0.01662813]\n",
      " [-0.82522166]\n",
      " [ 0.43156976]\n",
      " [-0.94003177]\n",
      " [ 0.15081604]\n",
      " [ 0.88516426]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 80: loss =   0.736, val_loss =   0.808, time:   1.466\n",
      "tf.Tensor(\n",
      "[[ 0.71409434]\n",
      " [ 0.11440261]\n",
      " [-0.04123497]\n",
      " [-0.21984677]\n",
      " [-0.38078457]\n",
      " [-0.44212943]\n",
      " [ 0.6411827 ]\n",
      " [-0.75940496]\n",
      " [-0.52409136]\n",
      " [ 0.9024553 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 81: loss =   0.740, val_loss =   0.825, time:   1.224\n",
      "tf.Tensor(\n",
      "[[ 0.7426422 ]\n",
      " [ 0.61516917]\n",
      " [-0.28423625]\n",
      " [-0.1836313 ]\n",
      " [-0.42875716]\n",
      " [-0.62003744]\n",
      " [ 0.38367438]\n",
      " [-0.92874134]\n",
      " [-0.3909183 ]\n",
      " [ 0.90370727]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 82: loss =   0.738, val_loss =   0.817, time:   1.240\n",
      "tf.Tensor(\n",
      "[[ 0.84761053]\n",
      " [ 0.7527896 ]\n",
      " [ 0.06143756]\n",
      " [-0.24220362]\n",
      " [ 0.22030412]\n",
      " [-0.07108621]\n",
      " [ 0.81683123]\n",
      " [-0.9060006 ]\n",
      " [-0.4247162 ]\n",
      " [ 0.96395177]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 83: loss =   0.750, val_loss =   0.821, time:   1.254\n",
      "tf.Tensor(\n",
      "[[ 0.81406045]\n",
      " [ 0.50322425]\n",
      " [ 0.24012206]\n",
      " [-0.20925966]\n",
      " [ 0.11579189]\n",
      " [ 0.25174028]\n",
      " [ 0.55665725]\n",
      " [-0.92444354]\n",
      " [-0.33629277]\n",
      " [ 0.86167324]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 84: loss =   0.746, val_loss =   0.821, time:   1.249\n",
      "tf.Tensor(\n",
      "[[ 0.7910817 ]\n",
      " [ 0.11747267]\n",
      " [ 0.17206164]\n",
      " [ 0.10634412]\n",
      " [-0.08122551]\n",
      " [-0.26705945]\n",
      " [ 0.45499256]\n",
      " [-0.9263691 ]\n",
      " [-0.9332934 ]\n",
      " [ 0.90370405]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 85: loss =   0.724, val_loss =   0.817, time:   1.240\n",
      "tf.Tensor(\n",
      "[[ 0.4136951 ]\n",
      " [ 0.50205654]\n",
      " [ 0.3499937 ]\n",
      " [-0.09476594]\n",
      " [-0.44359973]\n",
      " [-0.5866861 ]\n",
      " [ 0.5362683 ]\n",
      " [-0.9604935 ]\n",
      " [-0.5297013 ]\n",
      " [ 0.8977783 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 86: loss =   0.732, val_loss =   0.824, time:   1.348\n",
      "tf.Tensor(\n",
      "[[ 0.5660089 ]\n",
      " [ 0.23340079]\n",
      " [ 0.6253279 ]\n",
      " [ 0.21222894]\n",
      " [-0.24170096]\n",
      " [-0.4572362 ]\n",
      " [ 0.49086213]\n",
      " [-0.9491158 ]\n",
      " [-0.45916492]\n",
      " [ 0.9038339 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 87: loss =   0.756, val_loss =   0.814, time:   1.291\n",
      "tf.Tensor(\n",
      "[[ 0.9740709 ]\n",
      " [ 0.18632425]\n",
      " [-0.29551253]\n",
      " [-0.06387458]\n",
      " [-0.12723644]\n",
      " [-0.17076905]\n",
      " [ 0.57456756]\n",
      " [-0.9392797 ]\n",
      " [-0.7108167 ]\n",
      " [ 0.97276306]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 88: loss =   0.723, val_loss =   0.837, time:   1.327\n",
      "tf.Tensor(\n",
      "[[ 0.90767556]\n",
      " [ 0.705727  ]\n",
      " [ 0.2995564 ]\n",
      " [-0.1938694 ]\n",
      " [-0.0827141 ]\n",
      " [-0.03750014]\n",
      " [ 0.3059662 ]\n",
      " [-0.95299083]\n",
      " [-0.36682212]\n",
      " [ 0.9849089 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 89: loss =   0.726, val_loss =   0.839, time:   1.390\n",
      "tf.Tensor(\n",
      "[[ 0.9570026 ]\n",
      " [ 0.78730017]\n",
      " [-0.592409  ]\n",
      " [ 0.25553358]\n",
      " [ 0.07268216]\n",
      " [-0.6357918 ]\n",
      " [ 0.50312597]\n",
      " [-0.8219065 ]\n",
      " [-0.9639635 ]\n",
      " [ 0.59093356]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 90: loss =   0.730, val_loss =   0.831, time:   1.641\n",
      "tf.Tensor(\n",
      "[[ 0.9405162 ]\n",
      " [ 0.59107727]\n",
      " [-0.34402394]\n",
      " [-0.46108037]\n",
      " [-0.11943784]\n",
      " [-0.83750284]\n",
      " [ 0.6596446 ]\n",
      " [-0.941583  ]\n",
      " [-0.8689341 ]\n",
      " [ 0.72594005]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 91: loss =   0.722, val_loss =   0.820, time:   1.680\n",
      "tf.Tensor(\n",
      "[[ 0.67249054]\n",
      " [ 0.05484899]\n",
      " [-0.21019332]\n",
      " [-0.11752277]\n",
      " [ 0.01544619]\n",
      " [-0.09514521]\n",
      " [ 0.3880948 ]\n",
      " [-0.98823506]\n",
      " [-0.9494332 ]\n",
      " [ 0.82510406]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 92: loss =   0.723, val_loss =   0.835, time:   1.290\n",
      "tf.Tensor(\n",
      "[[ 0.75599074]\n",
      " [ 0.8129453 ]\n",
      " [-0.05840774]\n",
      " [ 0.20984249]\n",
      " [-0.08533577]\n",
      " [-0.6828662 ]\n",
      " [ 0.51891047]\n",
      " [-0.9828461 ]\n",
      " [-0.86887145]\n",
      " [ 0.8056525 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 93: loss =   0.726, val_loss =   0.822, time:   1.341\n",
      "tf.Tensor(\n",
      "[[ 0.8612109 ]\n",
      " [ 0.68387526]\n",
      " [-0.3112779 ]\n",
      " [-0.47703207]\n",
      " [-0.00805068]\n",
      " [-0.47946507]\n",
      " [ 0.6043668 ]\n",
      " [-0.9346025 ]\n",
      " [-0.9099569 ]\n",
      " [ 0.95138437]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 94: loss =   0.725, val_loss =   0.823, time:   1.261\n",
      "tf.Tensor(\n",
      "[[ 0.8433496 ]\n",
      " [ 0.5995687 ]\n",
      " [ 0.2639575 ]\n",
      " [-0.16489224]\n",
      " [ 0.06668019]\n",
      " [-0.5500892 ]\n",
      " [ 0.5025309 ]\n",
      " [-0.9622799 ]\n",
      " [-0.47014642]\n",
      " [ 0.91951823]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 95: loss =   0.713, val_loss =   0.819, time:   1.224\n",
      "tf.Tensor(\n",
      "[[ 0.9549591 ]\n",
      " [ 0.44215876]\n",
      " [ 0.21593426]\n",
      " [-0.10213241]\n",
      " [-0.18456736]\n",
      " [-0.32519296]\n",
      " [ 0.6916379 ]\n",
      " [-0.96661156]\n",
      " [-0.04880887]\n",
      " [ 0.9822999 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 96: loss =   0.724, val_loss =   0.820, time:   1.166\n",
      "tf.Tensor(\n",
      "[[ 0.963356  ]\n",
      " [ 0.33131036]\n",
      " [ 0.02635275]\n",
      " [-0.4835412 ]\n",
      " [-0.19427104]\n",
      " [-0.2311159 ]\n",
      " [ 0.7905047 ]\n",
      " [-0.97685015]\n",
      " [-0.6619703 ]\n",
      " [ 0.9771986 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 97: loss =   0.717, val_loss =   0.810, time:   1.083\n",
      "tf.Tensor(\n",
      "[[ 0.65907913]\n",
      " [ 0.5573372 ]\n",
      " [ 0.39953318]\n",
      " [-0.17878602]\n",
      " [-0.05906204]\n",
      " [-0.7461682 ]\n",
      " [ 0.81813675]\n",
      " [-0.96406597]\n",
      " [-0.5281971 ]\n",
      " [ 0.76488614]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 98: loss =   0.702, val_loss =   0.816, time:   1.199\n",
      "tf.Tensor(\n",
      "[[ 0.844767  ]\n",
      " [ 0.84641755]\n",
      " [-0.4166874 ]\n",
      " [-0.15206522]\n",
      " [ 0.3245699 ]\n",
      " [ 0.38035208]\n",
      " [ 0.84725505]\n",
      " [-0.9670163 ]\n",
      " [-0.79500157]\n",
      " [ 0.94884133]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 99: loss =   0.712, val_loss =   0.823, time:   1.200\n",
      "tf.Tensor(\n",
      "[[ 0.9419509 ]\n",
      " [ 0.45504746]\n",
      " [ 0.12881374]\n",
      " [-0.10441949]\n",
      " [-0.20130093]\n",
      " [-0.54690826]\n",
      " [ 0.7412249 ]\n",
      " [-0.9816758 ]\n",
      " [-0.02983086]\n",
      " [ 0.78303754]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 100: loss =   0.727, val_loss =   0.808, time:   1.210\n",
      "tf.Tensor(\n",
      "[[ 0.8517226 ]\n",
      " [ 0.4871772 ]\n",
      " [ 0.27557182]\n",
      " [-0.44216847]\n",
      " [-0.05856223]\n",
      " [-0.474777  ]\n",
      " [ 0.38973218]\n",
      " [-0.8517489 ]\n",
      " [-0.2933557 ]\n",
      " [ 0.96284044]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 101: loss =   0.703, val_loss =   0.819, time:   1.276\n",
      "tf.Tensor(\n",
      "[[ 0.84628636]\n",
      " [ 0.6562192 ]\n",
      " [ 0.0335196 ]\n",
      " [-0.7240329 ]\n",
      " [ 0.17581558]\n",
      " [-0.21677838]\n",
      " [ 0.82327867]\n",
      " [-0.9096745 ]\n",
      " [-0.2667889 ]\n",
      " [ 0.9588057 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 102: loss =   0.704, val_loss =   0.822, time:   1.281\n",
      "tf.Tensor(\n",
      "[[ 0.68852824]\n",
      " [ 0.5140347 ]\n",
      " [-0.1637736 ]\n",
      " [ 0.4435193 ]\n",
      " [ 0.08002632]\n",
      " [-0.810396  ]\n",
      " [ 0.3685579 ]\n",
      " [-0.8983777 ]\n",
      " [-0.44908297]\n",
      " [ 0.6431838 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 103: loss =   0.697, val_loss =   0.812, time:   1.282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.8044319 ]\n",
      " [ 0.3897777 ]\n",
      " [ 0.0863558 ]\n",
      " [ 0.04126542]\n",
      " [-0.21814384]\n",
      " [-0.3418143 ]\n",
      " [ 0.2940084 ]\n",
      " [-0.9765976 ]\n",
      " [-0.64335465]\n",
      " [ 0.57396775]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 104: loss =   0.694, val_loss =   0.815, time:   1.283\n",
      "tf.Tensor(\n",
      "[[ 0.9495794 ]\n",
      " [ 0.64082265]\n",
      " [ 0.17601685]\n",
      " [ 0.377904  ]\n",
      " [-0.222141  ]\n",
      " [-0.22968316]\n",
      " [ 0.4598488 ]\n",
      " [-0.98509747]\n",
      " [-0.5814592 ]\n",
      " [ 0.6938946 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 105: loss =   0.699, val_loss =   0.814, time:   1.258\n",
      "tf.Tensor(\n",
      "[[ 0.9214706 ]\n",
      " [ 0.5312642 ]\n",
      " [ 0.25378704]\n",
      " [ 0.17668104]\n",
      " [-0.04760589]\n",
      " [-0.373328  ]\n",
      " [ 0.62283826]\n",
      " [-0.9765748 ]\n",
      " [ 0.31896988]\n",
      " [ 0.80637234]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 106: loss =   0.692, val_loss =   0.820, time:   1.274\n",
      "tf.Tensor(\n",
      "[[ 0.96167237]\n",
      " [ 0.6833956 ]\n",
      " [-0.06827482]\n",
      " [ 0.3750799 ]\n",
      " [-0.5822196 ]\n",
      " [-0.0556183 ]\n",
      " [ 0.6465934 ]\n",
      " [-0.9541608 ]\n",
      " [-0.6281551 ]\n",
      " [ 0.9773839 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 107: loss =   0.693, val_loss =   0.819, time:   1.262\n",
      "tf.Tensor(\n",
      "[[ 0.96936   ]\n",
      " [ 0.29192042]\n",
      " [ 0.79941064]\n",
      " [ 0.04868019]\n",
      " [-0.41596615]\n",
      " [-0.04606701]\n",
      " [ 0.716912  ]\n",
      " [-0.9831608 ]\n",
      " [-0.80955786]\n",
      " [ 0.98903215]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 108: loss =   0.689, val_loss =   0.826, time:   1.266\n",
      "tf.Tensor(\n",
      "[[ 0.9017343 ]\n",
      " [ 0.71902037]\n",
      " [ 0.15131183]\n",
      " [-0.23837596]\n",
      " [-0.6878105 ]\n",
      " [ 0.1685405 ]\n",
      " [ 0.6241843 ]\n",
      " [-0.9942657 ]\n",
      " [-0.8325244 ]\n",
      " [ 0.98375905]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 109: loss =   0.689, val_loss =   0.824, time:   1.265\n",
      "tf.Tensor(\n",
      "[[ 0.8296429 ]\n",
      " [-0.10197186]\n",
      " [-0.52278167]\n",
      " [-0.3518203 ]\n",
      " [-0.69963163]\n",
      " [-0.12253463]\n",
      " [ 0.60501194]\n",
      " [-0.992051  ]\n",
      " [-0.9235272 ]\n",
      " [ 0.88552344]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 110: loss =   0.694, val_loss =   0.831, time:   1.266\n",
      "tf.Tensor(\n",
      "[[ 0.80565387]\n",
      " [ 0.2277765 ]\n",
      " [ 0.03059928]\n",
      " [ 0.37605608]\n",
      " [ 0.01202345]\n",
      " [-0.3381105 ]\n",
      " [ 0.76550376]\n",
      " [-0.9772151 ]\n",
      " [-0.50738806]\n",
      " [ 0.9771154 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 111: loss =   0.687, val_loss =   0.816, time:   1.273\n",
      "tf.Tensor(\n",
      "[[ 0.83631295]\n",
      " [ 0.3657544 ]\n",
      " [-0.32476255]\n",
      " [ 0.2414335 ]\n",
      " [-0.43986353]\n",
      " [-0.53886914]\n",
      " [ 0.7759303 ]\n",
      " [-0.9792694 ]\n",
      " [-0.6385263 ]\n",
      " [ 0.9686012 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 112: loss =   0.682, val_loss =   0.821, time:   1.199\n",
      "tf.Tensor(\n",
      "[[ 0.80900794]\n",
      " [ 0.29937515]\n",
      " [-0.3235632 ]\n",
      " [ 0.34584022]\n",
      " [-0.21467979]\n",
      " [-0.20431581]\n",
      " [ 0.6844565 ]\n",
      " [-0.98540306]\n",
      " [-0.27561125]\n",
      " [ 0.6865564 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 113: loss =   0.691, val_loss =   0.821, time:   1.202\n",
      "tf.Tensor(\n",
      "[[ 0.5658929 ]\n",
      " [ 0.46161038]\n",
      " [ 0.00257071]\n",
      " [-0.3716897 ]\n",
      " [-0.1385674 ]\n",
      " [-0.6481547 ]\n",
      " [ 0.46463597]\n",
      " [-0.9829561 ]\n",
      " [-0.76888573]\n",
      " [ 0.8911252 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 114: loss =   0.682, val_loss =   0.819, time:   1.115\n",
      "tf.Tensor(\n",
      "[[ 0.3924784 ]\n",
      " [ 0.48631585]\n",
      " [-0.17307414]\n",
      " [-0.10703281]\n",
      " [-0.17014599]\n",
      " [-0.28145665]\n",
      " [ 0.5024718 ]\n",
      " [-0.99189675]\n",
      " [-0.85630226]\n",
      " [ 0.94460094]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 115: loss =   0.682, val_loss =   0.825, time:   1.176\n",
      "tf.Tensor(\n",
      "[[ 0.47508168]\n",
      " [ 0.03358813]\n",
      " [ 0.3633175 ]\n",
      " [-0.17836261]\n",
      " [-0.0712193 ]\n",
      " [-0.00210315]\n",
      " [ 0.49316362]\n",
      " [-0.97334003]\n",
      " [-0.57314265]\n",
      " [ 0.6191121 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 116: loss =   0.677, val_loss =   0.823, time:   1.247\n",
      "tf.Tensor(\n",
      "[[ 0.8866674 ]\n",
      " [-0.00214625]\n",
      " [ 0.05321554]\n",
      " [ 0.0838804 ]\n",
      " [-0.11722375]\n",
      " [-0.3495077 ]\n",
      " [ 0.54978186]\n",
      " [-0.9609204 ]\n",
      " [ 0.34020573]\n",
      " [ 0.84860104]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 117: loss =   0.685, val_loss =   0.812, time:   1.239\n",
      "tf.Tensor(\n",
      "[[ 0.7392594 ]\n",
      " [ 0.28857043]\n",
      " [ 0.26942024]\n",
      " [ 0.37652755]\n",
      " [-0.1811371 ]\n",
      " [-0.45412332]\n",
      " [ 0.7364712 ]\n",
      " [-0.9467076 ]\n",
      " [ 0.10518367]\n",
      " [ 0.9482634 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 118: loss =   0.679, val_loss =   0.822, time:   1.241\n",
      "tf.Tensor(\n",
      "[[ 0.9714627 ]\n",
      " [ 0.4021157 ]\n",
      " [-0.18064007]\n",
      " [ 0.17942676]\n",
      " [-0.4529142 ]\n",
      " [-0.18249713]\n",
      " [ 0.40425235]\n",
      " [-0.96764535]\n",
      " [-0.65955406]\n",
      " [ 0.87930715]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 119: loss =   0.680, val_loss =   0.812, time:   1.387\n",
      "tf.Tensor(\n",
      "[[ 0.27604568]\n",
      " [-0.02271921]\n",
      " [-0.27358964]\n",
      " [-0.3225542 ]\n",
      " [-0.2930438 ]\n",
      " [-0.44610953]\n",
      " [ 0.6410628 ]\n",
      " [-0.9423751 ]\n",
      " [-0.699936  ]\n",
      " [ 0.9780005 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 120: loss =   0.670, val_loss =   0.828, time:   1.286\n",
      "tf.Tensor(\n",
      "[[ 0.9034724 ]\n",
      " [ 0.6520973 ]\n",
      " [-0.58945936]\n",
      " [-0.1442412 ]\n",
      " [-0.13970202]\n",
      " [-0.3023104 ]\n",
      " [ 0.60983664]\n",
      " [-0.9899104 ]\n",
      " [-0.7245749 ]\n",
      " [ 0.7762735 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 121: loss =   0.684, val_loss =   0.815, time:   1.285\n",
      "tf.Tensor(\n",
      "[[ 0.78938395]\n",
      " [ 0.5117142 ]\n",
      " [-0.08632711]\n",
      " [-0.05970751]\n",
      " [-0.28181925]\n",
      " [-0.3495326 ]\n",
      " [ 0.5198013 ]\n",
      " [-0.9919699 ]\n",
      " [-0.2178649 ]\n",
      " [ 0.9394302 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 122: loss =   0.667, val_loss =   0.822, time:   1.282\n",
      "tf.Tensor(\n",
      "[[ 0.84451574]\n",
      " [ 0.61254686]\n",
      " [-0.4667756 ]\n",
      " [-0.2605961 ]\n",
      " [-0.32077545]\n",
      " [-0.245484  ]\n",
      " [ 0.4193344 ]\n",
      " [-0.9787646 ]\n",
      " [-0.08005951]\n",
      " [ 0.9076848 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 123: loss =   0.669, val_loss =   0.827, time:   1.297\n",
      "tf.Tensor(\n",
      "[[ 0.8951393 ]\n",
      " [ 0.82339   ]\n",
      " [-0.07422511]\n",
      " [ 0.05523233]\n",
      " [-0.1369479 ]\n",
      " [-0.05860627]\n",
      " [ 0.78776795]\n",
      " [-0.9896801 ]\n",
      " [-0.49783486]\n",
      " [ 0.9474773 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 124: loss =   0.674, val_loss =   0.824, time:   1.297\n",
      "tf.Tensor(\n",
      "[[ 0.43943018]\n",
      " [-0.01713287]\n",
      " [-0.12699287]\n",
      " [ 0.15549941]\n",
      " [-0.49303326]\n",
      " [-0.13410904]\n",
      " [ 0.7084821 ]\n",
      " [-0.99312085]\n",
      " [-0.912369  ]\n",
      " [ 0.49349284]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 125: loss =   0.658, val_loss =   0.827, time:   1.341\n",
      "tf.Tensor(\n",
      "[[ 0.6789338 ]\n",
      " [-0.05284268]\n",
      " [-0.30899093]\n",
      " [ 0.09825359]\n",
      " [-0.5165695 ]\n",
      " [-0.28601876]\n",
      " [ 0.66606206]\n",
      " [-0.9869108 ]\n",
      " [-0.80558383]\n",
      " [ 0.9536106 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 126: loss =   0.659, val_loss =   0.830, time:   1.303\n",
      "tf.Tensor(\n",
      "[[ 0.74112463]\n",
      " [ 0.33244064]\n",
      " [-0.16140652]\n",
      " [-0.3656274 ]\n",
      " [-0.3871372 ]\n",
      " [-0.69763863]\n",
      " [ 0.6712824 ]\n",
      " [-0.97752   ]\n",
      " [-0.2788063 ]\n",
      " [ 0.9918892 ]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 127: loss =   0.666, val_loss =   0.821, time:   1.392\n",
      "tf.Tensor(\n",
      "[[ 0.8707807 ]\n",
      " [ 0.63977   ]\n",
      " [ 0.49469122]\n",
      " [ 0.49952593]\n",
      " [-0.03593798]\n",
      " [ 0.27737406]\n",
      " [ 0.7619744 ]\n",
      " [-0.9671604 ]\n",
      " [-0.16612156]\n",
      " [ 0.99718875]], shape=(10, 1), dtype=float32) [[ 1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [-1]]\n",
      "Epoch: 128: loss =   0.658, val_loss =   0.823, time:   1.442\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-7cffd101ddeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mval_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbcnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melbo_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m#val_acc = accuracy(y_train_big_1, val_preds)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    821\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    715\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    716\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    821\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_probability\\python\\layers\\dense_variational.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_variational_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_variational_bias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_probability\\python\\layers\\dense_variational.py\u001b[0m in \u001b[0;36m_apply_variational_kernel\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m         seed=seed_stream())\n\u001b[0m\u001b[0;32m    698\u001b[0m     sign_output = random_rademacher(\n\u001b[0;32m    699\u001b[0m         tf.concat([batch_shape,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_probability\\python\\math\\random_ops.py\u001b[0m in \u001b[0;36mrandom_rademacher\u001b[1;34m(shape, dtype, seed, name)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mgeneration_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     random_bernoulli = tf.random.uniform(\n\u001b[1;32m---> 57\u001b[1;33m         shape, minval=0, maxval=2, dtype=generation_dtype, seed=seed)\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mrandom_bernoulli\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m       result = gen_random_ops.random_uniform_int(\n\u001b[1;32m--> 270\u001b[1;33m           shape, minval, maxval, seed=seed1, seed2=seed2, name=name)\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m       \u001b[0mrnd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_random_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform_int\u001b[1;34m(shape, minval, maxval, seed, seed2, name)\u001b[0m\n\u001b[0;32m    803\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m    804\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"RandomUniformInt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m         tld.op_callbacks, shape, minval, maxval, \"seed\", seed, \"seed2\", seed2)\n\u001b[0m\u001b[0;32m    806\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "times = []\n",
    "accs = []\n",
    "val_accs = []\n",
    "losses = []\n",
    "val_losses = []\n",
    "for i in range(1000):\n",
    "    tic = time.time()\n",
    "    loss = train_step(X_train, y_train)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    val_preds = bcnn(X_test)\n",
    "    val_loss = elbo_loss(y_test, val_preds)\n",
    "    #val_acc = accuracy(y_train_big_1, val_preds)\n",
    "    print(val_preds[:10], y_test[:10])\n",
    "    \n",
    "    #val_accs.append(val_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    tac = time.time()\n",
    "    train_time = tac-tic\n",
    "    times.append(train_time)\n",
    "    \n",
    "    print(\"Epoch: {}: loss = {:7.3f}, val_loss = {:7.3f}, time: {:7.3f}\".format(i, loss, val_loss, train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(np.array(losses), label=\"loss\")\n",
    "plt.plot(np.array(val_losses), label=\"val_loss\")\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bcnn.save_weights(\"critic.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = bcnn(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4405348770485342\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_test, bcnn(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32044, 1), dtype=float32, numpy=\n",
       "array([[-0.9997102],\n",
       "       [-0.9884574],\n",
       "       [-0.8457604],\n",
       "       ...,\n",
       "       [ 1.       ],\n",
       "       [-1.       ],\n",
       "       [ 1.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcnn(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-113856c8d768>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_big_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_big_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_big_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\keras\\utils\\np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mcategorical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "keras.utils.to_categorical(y_train_big_1.reshape(len(y_train_big_1)) + np.ones((len(y_train_big_1),)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = y_train_big_1.reshape(len(y_train_big_1)) + np.ones((len(y_train_big_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(arr)):\n",
    "    if arr[i] == 2:\n",
    "        arr[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_big = keras.utils.to_categorical(arr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = y_train_big_2.reshape(len(y_train_big_2)) + np.ones((len(y_train_big_2)))\n",
    "for i in range(len(arr)):\n",
    "    if arr[i] == 2:\n",
    "        arr[i] = 1\n",
    "y_test = keras.utils.to_categorical(arr, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kl_divergence_function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-c2f6f994d1fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDenseFlipout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mtfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDenseFlipout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tanh'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_divergence_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkl_divergence_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;31m#tfp.layers.DenseFlipout(1, activation='tanh')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m ])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kl_divergence_function' is not defined"
     ]
    }
   ],
   "source": [
    "kernel_divergence_fn=lambda q, p, _: tfp.distributions.kl_divergence(q, p) / (x.shape[0] * 1.0)\n",
    "bias_divergence_fn=lambda q, p, _: tfp.distributions.kl_divergence(q, p) / (x.shape[0] * 1.0)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(X_train.shape[1],), name=\"basket\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tfp.layers.DenseFlipout(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tfp.layers.DenseFlipout(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tfp.layers.DenseFlipout(1, activation='tanh', kernel_divergence_fn=kl_divergence_function),\n",
    "    #tfp.layers.DenseFlipout(1, activation='tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1.0e-3\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 214406 samples, validate on 212198 samples\n",
      "Epoch 1/100\n",
      "214406/214406 [==============================] - 61s 285us/sample - loss: 422344.7958 - mse: 1.4628 - val_loss: 404302.2318 - val_mse: 1.0751\n",
      "Epoch 2/100\n",
      "214406/214406 [==============================] - 53s 246us/sample - loss: 386860.3004 - mse: 1.2647 - val_loss: 369235.6837 - val_mse: 1.1515\n",
      "Epoch 3/100\n",
      " 56320/214406 [======>.......................] - ETA: 21s - loss: 364848.4601 - mse: 1.2768"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-b4f9dab460f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=1024, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1782597842483173"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "def NLL(y, distr): \n",
    "    return -distr.log_prob(y) \n",
    "\n",
    "def normal_sp(params): \n",
    "    return tfd.Normal(loc=params[:,0:1], scale=1e-3 + tf.math.softplus(0.05 * params[:,1:2]))# both parameters are learnable\n",
    "\n",
    "kernel_divergence_fn=lambda q, p, _: tfp.distributions.kl_divergence(q, p) / (X_train.shape[0] * 1.0)\n",
    "bias_divergence_fn=lambda q, p, _: tfp.distributions.kl_divergence(q, p) / (X_train.shape[0] * 1.0)\n",
    "\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "inp = BatchNormalization()(inputs)\n",
    "hidden = tfp.layers.DenseFlipout(256,bias_posterior_fn=tfp.layers.util.default_mean_field_normal_fn(),\n",
    "                           bias_prior_fn=tfp.layers.default_multivariate_normal_fn,\n",
    "                           kernel_divergence_fn=kernel_divergence_fn,\n",
    "                           bias_divergence_fn=bias_divergence_fn,activation=\"relu\")(inp)\n",
    "do1 = tf.keras.layers.Dropout(0.2)(hidden)\n",
    "params = tfp.layers.DenseFlipout(1,activation=\"tanh\", bias_posterior_fn=tfp.layers.util.default_mean_field_normal_fn(),\n",
    "                           bias_prior_fn=tfp.layers.default_multivariate_normal_fn,\n",
    "                           kernel_divergence_fn=kernel_divergence_fn,\n",
    "                           bias_divergence_fn=bias_divergence_fn)(do1)\n",
    "#dist = tfp.layers.DistributionLambda(normal_sp)(params) \n",
    "\n",
    "\n",
    "model_vi = Model(inputs=inputs, outputs=params)\n",
    "#model_vi.compile(Adam(learning_rate=0.001), loss=NLL, metrics=['mse']) \n",
    "model_vi.compile(Adam(learning_rate=0.01), loss='mse', metrics=['mse']) \n",
    "model_params = Model(inputs=inputs, outputs=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21361 samples, validate on 21176 samples\n",
      "Epoch 1/100\n",
      "21361/21361 [==============================] - 6s 276us/sample - loss: 7.8212 - mse: 1.2206 - val_loss: 7.5987 - val_mse: 1.1430\n",
      "Epoch 2/100\n",
      "21361/21361 [==============================] - 2s 105us/sample - loss: 7.3253 - mse: 1.0002 - val_loss: 7.3217 - val_mse: 1.1426\n",
      "Epoch 3/100\n",
      "21361/21361 [==============================] - 2s 100us/sample - loss: 6.9912 - mse: 0.9433 - val_loss: 6.9912 - val_mse: 1.0894\n",
      "Epoch 4/100\n",
      "21361/21361 [==============================] - 2s 102us/sample - loss: 6.6623 - mse: 0.8903 - val_loss: 6.6332 - val_mse: 1.0049\n",
      "Epoch 5/100\n",
      "21361/21361 [==============================] - 2s 100us/sample - loss: 6.3438 - mse: 0.8428 - val_loss: 6.2884 - val_mse: 0.9283\n",
      "Epoch 6/100\n",
      "21361/21361 [==============================] - 2s 99us/sample - loss: 6.0122 - mse: 0.7763 - val_loss: 5.9627 - val_mse: 0.8644\n",
      "Epoch 7/100\n",
      "21361/21361 [==============================] - 2s 109us/sample - loss: 5.6973 - mse: 0.7211 - val_loss: 5.6591 - val_mse: 0.8186\n",
      "Epoch 8/100\n",
      "21361/21361 [==============================] - 2s 106us/sample - loss: 5.4111 - mse: 0.6922 - val_loss: 5.3837 - val_mse: 0.8005\n",
      "Epoch 9/100\n",
      "21361/21361 [==============================] - 2s 108us/sample - loss: 5.1305 - mse: 0.6685 - val_loss: 5.1151 - val_mse: 0.7875\n",
      "Epoch 10/100\n",
      "21361/21361 [==============================] - 2s 106us/sample - loss: 4.8755 - mse: 0.6673 - val_loss: 4.8641 - val_mse: 0.7881\n",
      "Epoch 11/100\n",
      "21361/21361 [==============================] - 2s 117us/sample - loss: 4.6182 - mse: 0.6586 - val_loss: 4.6157 - val_mse: 0.7845\n",
      "Epoch 12/100\n",
      "21361/21361 [==============================] - 2s 110us/sample - loss: 4.3684 - mse: 0.6504 - val_loss: 4.3919 - val_mse: 0.7989\n",
      "Epoch 13/100\n",
      "21361/21361 [==============================] - 2s 105us/sample - loss: 4.1265 - mse: 0.6438 - val_loss: 4.1442 - val_mse: 0.7826\n",
      "Epoch 14/100\n",
      "21361/21361 [==============================] - 2s 110us/sample - loss: 3.9025 - mse: 0.6470 - val_loss: 3.9346 - val_mse: 0.7957\n",
      "Epoch 15/100\n",
      "21361/21361 [==============================] - 2s 113us/sample - loss: 3.6964 - mse: 0.6586 - val_loss: 3.7139 - val_mse: 0.7873\n",
      "Epoch 16/100\n",
      "21361/21361 [==============================] - 2s 107us/sample - loss: 3.4906 - mse: 0.6607 - val_loss: 3.5080 - val_mse: 0.7840\n",
      "Epoch 17/100\n",
      "21361/21361 [==============================] - 2s 108us/sample - loss: 3.2876 - mse: 0.6562 - val_loss: 3.3269 - val_mse: 0.7971\n",
      "Epoch 18/100\n",
      "21361/21361 [==============================] - 2s 115us/sample - loss: 3.0992 - mse: 0.6572 - val_loss: 3.1305 - val_mse: 0.7845\n",
      "Epoch 19/100\n",
      "21361/21361 [==============================] - 2s 99us/sample - loss: 2.9218 - mse: 0.6587 - val_loss: 2.9738 - val_mse: 0.8010\n",
      "Epoch 20/100\n",
      "21361/21361 [==============================] - 2s 100us/sample - loss: 2.7599 - mse: 0.6651 - val_loss: 2.8111 - val_mse: 0.8012\n",
      "Epoch 21/100\n",
      "21361/21361 [==============================] - 2s 97us/sample - loss: 2.5973 - mse: 0.6601 - val_loss: 2.6534 - val_mse: 0.7959\n",
      "Epoch 22/100\n",
      "21361/21361 [==============================] - 2s 98us/sample - loss: 2.4564 - mse: 0.6670 - val_loss: 2.5086 - val_mse: 0.7931\n",
      "Epoch 23/100\n",
      "21361/21361 [==============================] - 2s 111us/sample - loss: 2.3253 - mse: 0.6724 - val_loss: 2.3823 - val_mse: 0.7975\n",
      "Epoch 24/100\n",
      "21361/21361 [==============================] - 2s 107us/sample - loss: 2.1907 - mse: 0.6646 - val_loss: 2.2547 - val_mse: 0.7922\n",
      "Epoch 25/100\n",
      " 7168/21361 [=========>....................] - ETA: 0s - loss: 2.1329 - mse: 0.6844"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-ab405646b7bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_vi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_vi.fit(X_train, y_train, epochs=100, batch_size=1024, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, model_vi.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.110635  ],\n",
       "       [ 0.31213433],\n",
       "       [ 0.4475886 ],\n",
       "       [-0.34117684],\n",
       "       [ 0.02357351],\n",
       "       [-0.1377169 ],\n",
       "       [-0.00382401],\n",
       "       [ 0.35468742],\n",
       "       [-0.23620737],\n",
       "       [-0.08607194]], dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vi.predict(X_test[:10].reshape(10, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [-1.],\n",
       "       [ 1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [ 1.],\n",
       "       [-1.],\n",
       "       [ 1.],\n",
       "       [-1.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.542389368827469"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, model_vi.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32806292],\n",
       "       [-0.46644053],\n",
       "       [-1.4164567 ],\n",
       "       [ 0.09548746],\n",
       "       [-0.5884465 ],\n",
       "       [ 0.29557213],\n",
       "       [-0.01731414],\n",
       "       [ 0.41492966],\n",
       "       [ 0.88287306],\n",
       "       [ 0.21522072]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vi.predict(X_test[:10].reshape(10, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "  \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(424,)),\n",
    "    tfp.layers.DenseFlipout(256, activation='relu'),\n",
    "    tfp.layers.DenseFlipout(units=1, activation='tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='mse', optimizer=Adam(lr=0.03), metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_37 to have shape (424,) but got array with shape (220,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-b4f9dab460f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\envs\\GDL\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    580\u001b[0m                              \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m                              str(data_shape))\n\u001b[0m\u001b[0;32m    583\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_37 to have shape (424,) but got array with shape (220,)"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=1024, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [-1.]], dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:10].reshape(10, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
